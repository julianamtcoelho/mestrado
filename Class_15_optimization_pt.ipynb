{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e431247-ff19-410a-9424-84090afa63ed",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.004214,
     "end_time": "2023-02-05T05:59:39.708260",
     "exception": false,
     "start_time": "2023-02-05T05:59:39.704046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Class ** - Hyperparameter Optimization \n",
    "\n",
    "---\n",
    "## Parameters in ML models\n",
    "> - O objetivo de um algoritmo de aprendizado típico é encontrar uma função `f` que minimize uma certa `perda` sobre um `conjunto de dados`.\n",
    "> - O algoritmo de aprendizado produz `f` através da otimização de um critério de treinamento em relação a um conjunto de `parâmetros`.\n",
    "\n",
    "---\n",
    "\n",
    "## Hiperparâmetros em modelos de ML\n",
    "> - Hiperparâmetros são parâmetros que não são aprendidos diretamente pelo algoritmo de aprendizado.\n",
    "> - Os hiperparâmetros são especificados fora do procedimento de treinamento.\n",
    "> - Os hiperparâmetros controlam a capacidade do modelo, ou seja, o quão flexível o modelo é para ajustar os dados.\n",
    "> - Evite o ajuste excessivo.\n",
    "> - Os hiperparâmetros podem ter um grande impacto no desempenho do algoritmo de aprendizado.\n",
    "> - As configurações ideais de hiperparâmetros geralmente diferem para diferentes conjuntos de dados. Portanto, eles devem ser otimizados para cada conjunto de dados.\n",
    "---\n",
    "\n",
    "## Natureza do hiperparâmetro\n",
    ">- Alguns hiperparâmetros são discretos: Número de estimadores em modelos de conjunto.\n",
    ">- Alguns hiperparâmetros são contínuos: Coeficiente de penalização, Número de amostras por divisão.\n",
    ">- Alguns hiperparâmetros são categóricos: Perda (deviance, exponencial), Regularização (Lasso, Ridge)\n",
    "\n",
    "---\n",
    "\n",
    "## Parâmetros vs Hiperparâmetros\n",
    "\n",
    "|Parâmetros | Hiperparâmetros |\n",
    "|:-------------------------|---------------------- :|\n",
    "| - Intrínseco à equação do modelo | - Definido antes do treino |\n",
    "| - Otimizado durante o treinamento | - Restringir o algoritmo|\n",
    "\n",
    "> - O processo de encontrar os melhores hiperparâmetros para um determinado conjunto de dados é chamado de `Ajuste de hiperparâmetro` ou `Otimização de hiperparâmetro`.\n",
    "\n",
    "---\n",
    "\n",
    "## Desafios\n",
    ">- Não podemos definir uma fórmula para encontrar os hiperparâmetros.\n",
    ">- Experimente diferentes combinações de hiperparâmetros e avalie o desempenho do modelo. O passo crítico é escolher quantas combinações diferentes vamos testar.\n",
    "\n",
    "O número de combinações de hiperparâmetros ---> a chance de obter um modelo melhor ---> Custo computacional\n",
    "\n",
    ">- Como encontramos as combinações de hiperparâmetros para maximizar o desempenho enquanto diminuímos os custos computacionais?\n",
    "\n",
    "---\n",
    "\n",
    "## Métodos\n",
    "Diferentes estratégias de otimização de hiperparâmetros:\n",
    ">- Pesquisa manual\n",
    ">- Pesquisa em Grade\n",
    ">- Pesquisa Aleatória\n",
    ">- Otimização bayesiana\n",
    "\n",
    "---\n",
    "\n",
    "## Generalização x Sobreajuste\n",
    "> A generalização é a capacidade de um algoritmo ser eficaz em várias entradas. O desempenho do modelo de aprendizado de máquina é constante em diferentes conjuntos de dados (com a mesma distribuição nos dados de treinamento). Quando o modelo funciona bem no conjunto de treinamento, mas não em dados novos/ingênuos, o modelo superajusta os dados de treinamento.\n",
    "\n",
    "---\n",
    "\n",
    "## Como treinar um modelo de aprendizado de máquina\n",
    "> Para evitar o ajuste excessivo, é prática comum:\n",
    "> - Separe os dados em um trem e um conjunto de teste.\n",
    "> - Treine o modelo no conjunto de trens.\n",
    "> - Avalie no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91b4a1c7-a424-4c20-8ab9-aeb287a57032",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "N_FOLDS = 5\n",
    "MAX_EVALS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de3ca72e-8845-4679-88dd-d5c8b30612cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pclass</th>\n      <th>survived</th>\n      <th>name</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>ticket</th>\n      <th>fare</th>\n      <th>cabin</th>\n      <th>embarked</th>\n      <th>boat</th>\n      <th>body</th>\n      <th>home.dest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Allen, Miss. Elisabeth Walton</td>\n      <td>female</td>\n      <td>29.0000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24160</td>\n      <td>211.3375</td>\n      <td>B5</td>\n      <td>S</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>St Louis, MO</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Allison, Master. Hudson Trevor</td>\n      <td>male</td>\n      <td>0.9167</td>\n      <td>1</td>\n      <td>2</td>\n      <td>113781</td>\n      <td>151.5500</td>\n      <td>C22</td>\n      <td>S</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>Allison, Miss. Helen Loraine</td>\n      <td>female</td>\n      <td>2.0000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>113781</td>\n      <td>151.5500</td>\n      <td>C22</td>\n      <td>S</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>Allison, Mr. Hudson Joshua Creighton</td>\n      <td>male</td>\n      <td>30.0000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>113781</td>\n      <td>151.5500</td>\n      <td>C22</td>\n      <td>S</td>\n      <td>NaN</td>\n      <td>135.0</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n      <td>female</td>\n      <td>25.0000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>113781</td>\n      <td>151.5500</td>\n      <td>C22</td>\n      <td>S</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Montreal, PQ / Chesterville, ON</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": "<div class=\"ansiout\">Out[17]: </div>",
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('/dbfs/FileStore/CDS2023/titanic.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f73ce3c4-e511-449c-86e0-c51717393685",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[63]: ((1047, 8), (262, 8))</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[63]: ((1047, 8), (262, 8))</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data.drop(['pclass', 'name', 'home.dest', 'sex', 'cabin', 'embarked'], axis=1)\n",
    "Y = data['pclass']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "981fac6f-ffcc-441e-b21f-724d6b3cf4e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Random search\n",
    "\n",
    "## Pesquisa aleatória\n",
    "\n",
    "A pesquisa aleatória é surpreendentemente eficiente em comparação com a pesquisa em grade. Ele faz um trabalho melhor ao explorar o espaço de busca e, portanto, geralmente pode encontrar uma boa combinação de hiperparâmetros em muito menos iterações. Ele configura uma grade de valores de hiperparâmetros e seleciona **combinações aleatórias** da grade para treinar o modelo e pontuar. O número de iterações de pesquisa é definido com base no tempo/recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfdfdfa2-93af-496e-aaee-fdbc3f2ff9a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c91e0eb2-15c5-4ea7-844f-46e34b992a99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define evaluation\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8591185-eac4-4c21-bc93-acca82644197",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Em seguida, podemos definir o espaço de busca.\n",
    "\n",
    "Este é um dicionário onde os nomes são argumentos para o modelo e os valores são distribuições das quais se extraem amostras. Otimizaremos o solucionador, a penalidade e os hiperparâmetros C do modelo com distribuições discretas para o tipo de solucionador e penalidade e uma distribuição log-uniforme de 1e-5 a 100 para o valor C.\n",
    "\n",
    "Log-uniforme é útil para pesquisar valores de penalidade, pois geralmente exploramos valores em diferentes ordens de magnitude, pelo menos como uma primeira etapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3f2cf5e-c3a5-483a-be2e-16c00ad0d126",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define search space\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l2', 'elasticnet']\n",
    "space['C'] = loguniform(1e-5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d23dd9f-5d4a-4159-bb28-602649af2e81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b54d621c-4ed3-4393-bc5b-3c47525a26da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty=&#39;none&#39; will ignore the C and l1_ratio parameters\n",
       "  &#34;Setting penalty=&#39;none&#39; will ignore the C and l1_ratio &#34;\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty=&#39;none&#39; will ignore the C and l1_ratio parameters\n  &#34;Setting penalty=&#39;none&#39; will ignore the C and l1_ratio &#34;\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-150186281022610&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># execute search</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>result <span class=\"ansi-blue-fg\">=</span> search<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> Y<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> <span class=\"ansi-red-fg\"># summarize result</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;Best Score: %s&#39;</span> <span class=\"ansi-blue-fg\">%</span> result<span class=\"ansi-blue-fg\">.</span>best_score_<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;Best Hyperparameters: %s&#39;</span> <span class=\"ansi-blue-fg\">%</span> result<span class=\"ansi-blue-fg\">.</span>best_params_<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">inner_f</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                           FutureWarning)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         kwargs<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>k<span class=\"ansi-blue-fg\">:</span> arg <span class=\"ansi-green-fg\">for</span> k<span class=\"ansi-blue-fg\">,</span> arg <span class=\"ansi-green-fg\">in</span> zip<span class=\"ansi-blue-fg\">(</span>sig<span class=\"ansi-blue-fg\">.</span>parameters<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 73</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>     <span class=\"ansi-green-fg\">return</span> inner_f\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     75</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/model_selection/_search.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, X, y, groups, **fit_params)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    763</span>             refit_start_time <span class=\"ansi-blue-fg\">=</span> time<span class=\"ansi-blue-fg\">.</span>time<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    764</span>             <span class=\"ansi-green-fg\">if</span> y <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 765</span><span class=\"ansi-red-fg\">                 </span>self<span class=\"ansi-blue-fg\">.</span>best_estimator_<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> y<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>fit_params<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    766</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    767</span>                 self<span class=\"ansi-blue-fg\">.</span>best_estimator_<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>fit_params<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, X, y, sample_weight)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1342</span>         X, y = self._validate_data(X, y, accept_sparse=&#39;csr&#39;, dtype=_dtype,\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1343</span>                                    order<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#34;C&#34;</span><span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1344</span><span class=\"ansi-red-fg\">                                    accept_large_sparse=solver != &#39;liblinear&#39;)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1345</span>         check_classification_targets<span class=\"ansi-blue-fg\">(</span>y<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1346</span>         self<span class=\"ansi-blue-fg\">.</span>classes_ <span class=\"ansi-blue-fg\">=</span> np<span class=\"ansi-blue-fg\">.</span>unique<span class=\"ansi-blue-fg\">(</span>y<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/base.py</span> in <span class=\"ansi-cyan-fg\">_validate_data</span><span class=\"ansi-blue-fg\">(self, X, y, reset, validate_separately, **check_params)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    430</span>                 y <span class=\"ansi-blue-fg\">=</span> check_array<span class=\"ansi-blue-fg\">(</span>y<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>check_y_params<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    431</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 432</span><span class=\"ansi-red-fg\">                 </span>X<span class=\"ansi-blue-fg\">,</span> y <span class=\"ansi-blue-fg\">=</span> check_X_y<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> y<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>check_params<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    433</span>             out <span class=\"ansi-blue-fg\">=</span> X<span class=\"ansi-blue-fg\">,</span> y\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    434</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">inner_f</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                           FutureWarning)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         kwargs<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>k<span class=\"ansi-blue-fg\">:</span> arg <span class=\"ansi-green-fg\">for</span> k<span class=\"ansi-blue-fg\">,</span> arg <span class=\"ansi-green-fg\">in</span> zip<span class=\"ansi-blue-fg\">(</span>sig<span class=\"ansi-blue-fg\">.</span>parameters<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 73</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>     <span class=\"ansi-green-fg\">return</span> inner_f\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     75</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">check_X_y</span><span class=\"ansi-blue-fg\">(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    801</span>                     ensure_min_samples<span class=\"ansi-blue-fg\">=</span>ensure_min_samples<span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    802</span>                     ensure_min_features<span class=\"ansi-blue-fg\">=</span>ensure_min_features<span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 803</span><span class=\"ansi-red-fg\">                     estimator=estimator)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">    804</span>     <span class=\"ansi-green-fg\">if</span> multi_output<span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    805</span>         y = check_array(y, accept_sparse=&#39;csr&#39;, force_all_finite=True,\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">inner_f</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                           FutureWarning)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         kwargs<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>k<span class=\"ansi-blue-fg\">:</span> arg <span class=\"ansi-green-fg\">for</span> k<span class=\"ansi-blue-fg\">,</span> arg <span class=\"ansi-green-fg\">in</span> zip<span class=\"ansi-blue-fg\">(</span>sig<span class=\"ansi-blue-fg\">.</span>parameters<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 73</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>     <span class=\"ansi-green-fg\">return</span> inner_f\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     75</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">check_array</span><span class=\"ansi-blue-fg\">(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    597</span>                     array <span class=\"ansi-blue-fg\">=</span> array<span class=\"ansi-blue-fg\">.</span>astype<span class=\"ansi-blue-fg\">(</span>dtype<span class=\"ansi-blue-fg\">,</span> casting<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#34;unsafe&#34;</span><span class=\"ansi-blue-fg\">,</span> copy<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    598</span>                 <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 599</span><span class=\"ansi-red-fg\">                     </span>array <span class=\"ansi-blue-fg\">=</span> np<span class=\"ansi-blue-fg\">.</span>asarray<span class=\"ansi-blue-fg\">(</span>array<span class=\"ansi-blue-fg\">,</span> order<span class=\"ansi-blue-fg\">=</span>order<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">=</span>dtype<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    600</span>             <span class=\"ansi-green-fg\">except</span> ComplexWarning<span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    601</span>                 raise ValueError(&#34;Complex data not supported\\n&#34;\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/numpy/core/_asarray.py</span> in <span class=\"ansi-cyan-fg\">asarray</span><span class=\"ansi-blue-fg\">(a, dtype, order)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     83</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     84</span>     &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-fg\">---&gt; 85</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> array<span class=\"ansi-blue-fg\">(</span>a<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">,</span> copy<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span> order<span class=\"ansi-blue-fg\">=</span>order<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     86</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/pandas/core/generic.py</span> in <span class=\"ansi-cyan-fg\">__array__</span><span class=\"ansi-blue-fg\">(self, dtype)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1991</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1992</span>     <span class=\"ansi-green-fg\">def</span> __array__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">:</span> NpDtype <span class=\"ansi-blue-fg\">|</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> np<span class=\"ansi-blue-fg\">.</span>ndarray<span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1993</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> np<span class=\"ansi-blue-fg\">.</span>asarray<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_values<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">=</span>dtype<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1994</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1995</span>     def __array_wrap__(\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/numpy/core/_asarray.py</span> in <span class=\"ansi-cyan-fg\">asarray</span><span class=\"ansi-blue-fg\">(a, dtype, order)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     83</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     84</span>     &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-fg\">---&gt; 85</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> array<span class=\"ansi-blue-fg\">(</span>a<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">,</span> copy<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span> order<span class=\"ansi-blue-fg\">=</span>order<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     86</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n",
       "\n",
       "<span class=\"ansi-red-fg\">ValueError</span>: could not convert string to float: &#39;PC 17609&#39;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-150186281022610&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># execute search</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>result <span class=\"ansi-blue-fg\">=</span> search<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> Y<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> <span class=\"ansi-red-fg\"># summarize result</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;Best Score: %s&#39;</span> <span class=\"ansi-blue-fg\">%</span> result<span class=\"ansi-blue-fg\">.</span>best_score_<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;Best Hyperparameters: %s&#39;</span> <span class=\"ansi-blue-fg\">%</span> result<span class=\"ansi-blue-fg\">.</span>best_params_<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">inner_f</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                           FutureWarning)\n<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         kwargs<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>k<span class=\"ansi-blue-fg\">:</span> arg <span class=\"ansi-green-fg\">for</span> k<span class=\"ansi-blue-fg\">,</span> arg <span class=\"ansi-green-fg\">in</span> zip<span class=\"ansi-blue-fg\">(</span>sig<span class=\"ansi-blue-fg\">.</span>parameters<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 73</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>     <span class=\"ansi-green-fg\">return</span> inner_f\n<span class=\"ansi-green-intense-fg ansi-bold\">     75</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/model_selection/_search.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, X, y, groups, **fit_params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    763</span>             refit_start_time <span class=\"ansi-blue-fg\">=</span> time<span class=\"ansi-blue-fg\">.</span>time<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    764</span>             <span class=\"ansi-green-fg\">if</span> y <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 765</span><span class=\"ansi-red-fg\">                 </span>self<span class=\"ansi-blue-fg\">.</span>best_estimator_<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> y<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>fit_params<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    766</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    767</span>                 self<span class=\"ansi-blue-fg\">.</span>best_estimator_<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>fit_params<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, X, y, sample_weight)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1342</span>         X, y = self._validate_data(X, y, accept_sparse=&#39;csr&#39;, dtype=_dtype,\n<span class=\"ansi-green-intense-fg ansi-bold\">   1343</span>                                    order<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#34;C&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">-&gt; 1344</span><span class=\"ansi-red-fg\">                                    accept_large_sparse=solver != &#39;liblinear&#39;)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1345</span>         check_classification_targets<span class=\"ansi-blue-fg\">(</span>y<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1346</span>         self<span class=\"ansi-blue-fg\">.</span>classes_ <span class=\"ansi-blue-fg\">=</span> np<span class=\"ansi-blue-fg\">.</span>unique<span class=\"ansi-blue-fg\">(</span>y<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/base.py</span> in <span class=\"ansi-cyan-fg\">_validate_data</span><span class=\"ansi-blue-fg\">(self, X, y, reset, validate_separately, **check_params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    430</span>                 y <span class=\"ansi-blue-fg\">=</span> check_array<span class=\"ansi-blue-fg\">(</span>y<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>check_y_params<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    431</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 432</span><span class=\"ansi-red-fg\">                 </span>X<span class=\"ansi-blue-fg\">,</span> y <span class=\"ansi-blue-fg\">=</span> check_X_y<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> y<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>check_params<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    433</span>             out <span class=\"ansi-blue-fg\">=</span> X<span class=\"ansi-blue-fg\">,</span> y\n<span class=\"ansi-green-intense-fg ansi-bold\">    434</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">inner_f</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                           FutureWarning)\n<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         kwargs<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>k<span class=\"ansi-blue-fg\">:</span> arg <span class=\"ansi-green-fg\">for</span> k<span class=\"ansi-blue-fg\">,</span> arg <span class=\"ansi-green-fg\">in</span> zip<span class=\"ansi-blue-fg\">(</span>sig<span class=\"ansi-blue-fg\">.</span>parameters<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 73</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>     <span class=\"ansi-green-fg\">return</span> inner_f\n<span class=\"ansi-green-intense-fg ansi-bold\">     75</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">check_X_y</span><span class=\"ansi-blue-fg\">(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    801</span>                     ensure_min_samples<span class=\"ansi-blue-fg\">=</span>ensure_min_samples<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    802</span>                     ensure_min_features<span class=\"ansi-blue-fg\">=</span>ensure_min_features<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">--&gt; 803</span><span class=\"ansi-red-fg\">                     estimator=estimator)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    804</span>     <span class=\"ansi-green-fg\">if</span> multi_output<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    805</span>         y = check_array(y, accept_sparse=&#39;csr&#39;, force_all_finite=True,\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">inner_f</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                           FutureWarning)\n<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         kwargs<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>k<span class=\"ansi-blue-fg\">:</span> arg <span class=\"ansi-green-fg\">for</span> k<span class=\"ansi-blue-fg\">,</span> arg <span class=\"ansi-green-fg\">in</span> zip<span class=\"ansi-blue-fg\">(</span>sig<span class=\"ansi-blue-fg\">.</span>parameters<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 73</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>     <span class=\"ansi-green-fg\">return</span> inner_f\n<span class=\"ansi-green-intense-fg ansi-bold\">     75</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">check_array</span><span class=\"ansi-blue-fg\">(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    597</span>                     array <span class=\"ansi-blue-fg\">=</span> array<span class=\"ansi-blue-fg\">.</span>astype<span class=\"ansi-blue-fg\">(</span>dtype<span class=\"ansi-blue-fg\">,</span> casting<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#34;unsafe&#34;</span><span class=\"ansi-blue-fg\">,</span> copy<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    598</span>                 <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 599</span><span class=\"ansi-red-fg\">                     </span>array <span class=\"ansi-blue-fg\">=</span> np<span class=\"ansi-blue-fg\">.</span>asarray<span class=\"ansi-blue-fg\">(</span>array<span class=\"ansi-blue-fg\">,</span> order<span class=\"ansi-blue-fg\">=</span>order<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">=</span>dtype<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    600</span>             <span class=\"ansi-green-fg\">except</span> ComplexWarning<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    601</span>                 raise ValueError(&#34;Complex data not supported\\n&#34;\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/numpy/core/_asarray.py</span> in <span class=\"ansi-cyan-fg\">asarray</span><span class=\"ansi-blue-fg\">(a, dtype, order)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     83</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     84</span>     &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">---&gt; 85</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> array<span class=\"ansi-blue-fg\">(</span>a<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">,</span> copy<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span> order<span class=\"ansi-blue-fg\">=</span>order<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     86</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/pandas/core/generic.py</span> in <span class=\"ansi-cyan-fg\">__array__</span><span class=\"ansi-blue-fg\">(self, dtype)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1991</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1992</span>     <span class=\"ansi-green-fg\">def</span> __array__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">:</span> NpDtype <span class=\"ansi-blue-fg\">|</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> np<span class=\"ansi-blue-fg\">.</span>ndarray<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1993</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> np<span class=\"ansi-blue-fg\">.</span>asarray<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_values<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">=</span>dtype<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1994</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1995</span>     def __array_wrap__(\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/numpy/core/_asarray.py</span> in <span class=\"ansi-cyan-fg\">asarray</span><span class=\"ansi-blue-fg\">(a, dtype, order)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     83</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     84</span>     &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">---&gt; 85</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> array<span class=\"ansi-blue-fg\">(</span>a<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">,</span> copy<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span> order<span class=\"ansi-blue-fg\">=</span>order<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     86</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n\n<span class=\"ansi-red-fg\">ValueError</span>: could not convert string to float: &#39;PC 17609&#39;</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">ValueError</span>: could not convert string to float: &#39;PC 17609&#39;",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# execute search\n",
    "result = search.fit(X, Y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20a05be1-2ef5-48d9-a2b1-f4d809cd01ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Pesquisa em Grade\n",
    "  Ele configura uma grade de valores de hiperparâmetros e, para cada combinação, treina um modelo e pontua nos dados de validação. Nesta abordagem, **cada combinação única de valores de hiperparâmetros é tentada**, o que pode ser muito ineficiente!\n",
    "\n",
    ">- Pesquisa exaustiva por meio de um subconjunto especificado de hiperparâmetros de um algoritmo de aprendizado.\n",
    ">- Examina todas as combinações possíveis dos hiperparâmetros especificados (produto cartesiano de hiperparâmetros).\n",
    "\n",
    "### Limitações\n",
    ">- Maldição da dimensionalidade: as combinações possíveis crescem exponencialmente com o número de hiperparâmetros.\n",
    ">- Computacionalmente caro.\n",
    ">- Os valores dos hiperparâmetros são determinados manualmente.\n",
    ">- Não é ideal para hiperparâmetros contínuos.\n",
    ">- Não explora todo o espaço de hiperparâmetros (não é viável).\n",
    ">- Tem um desempenho pior do que outras pesquisas (para modelos com espaços de hiperparâmetros complexos).\n",
    "\n",
    "### Vantagens\n",
    ">- Para modelos com espaços de hiperparâmetros mais simples funciona bem.\n",
    ">- Pode ser paralelizado.\n",
    "\n",
    "Grid Search é o método mais caro em termos de tempo total de computação. No entanto, se executado em paralelo, é rápido em termos de tempo de relógio de parede. Às vezes, executamos uma pequena grade, determinamos onde está o ótimo e expandimos a grade nessa direção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3f8ae45-6426-4874-acf1-1d51826773be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f86fc334-c332-4b2e-aee0-e39a4c36fe38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "140bf1c3-e43b-4092-9245-b31676e5aa1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty=&#39;none&#39; will ignore the C and l1_ratio parameters\n",
       "  &#34;Setting penalty=&#39;none&#39; will ignore the C and l1_ratio &#34;\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty=&#39;none&#39; will ignore the C and l1_ratio parameters\n  &#34;Setting penalty=&#39;none&#39; will ignore the C and l1_ratio &#34;\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-4371513980580996&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># execute search</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>result <span class=\"ansi-blue-fg\">=</span> search<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> Y<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> <span class=\"ansi-red-fg\"># summarize result</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;Best Score: %s&#39;</span> <span class=\"ansi-blue-fg\">%</span> result<span class=\"ansi-blue-fg\">.</span>best_score_<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;Best Hyperparameters: %s&#39;</span> <span class=\"ansi-blue-fg\">%</span> result<span class=\"ansi-blue-fg\">.</span>best_params_<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">inner_f</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                           FutureWarning)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         kwargs<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>k<span class=\"ansi-blue-fg\">:</span> arg <span class=\"ansi-green-fg\">for</span> k<span class=\"ansi-blue-fg\">,</span> arg <span class=\"ansi-green-fg\">in</span> zip<span class=\"ansi-blue-fg\">(</span>sig<span class=\"ansi-blue-fg\">.</span>parameters<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 73</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>     <span class=\"ansi-green-fg\">return</span> inner_f\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     75</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/model_selection/_search.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, X, y, groups, **fit_params)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    763</span>             refit_start_time <span class=\"ansi-blue-fg\">=</span> time<span class=\"ansi-blue-fg\">.</span>time<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    764</span>             <span class=\"ansi-green-fg\">if</span> y <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 765</span><span class=\"ansi-red-fg\">                 </span>self<span class=\"ansi-blue-fg\">.</span>best_estimator_<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> y<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>fit_params<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    766</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    767</span>                 self<span class=\"ansi-blue-fg\">.</span>best_estimator_<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>fit_params<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, X, y, sample_weight)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1342</span>         X, y = self._validate_data(X, y, accept_sparse=&#39;csr&#39;, dtype=_dtype,\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1343</span>                                    order<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#34;C&#34;</span><span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1344</span><span class=\"ansi-red-fg\">                                    accept_large_sparse=solver != &#39;liblinear&#39;)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1345</span>         check_classification_targets<span class=\"ansi-blue-fg\">(</span>y<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1346</span>         self<span class=\"ansi-blue-fg\">.</span>classes_ <span class=\"ansi-blue-fg\">=</span> np<span class=\"ansi-blue-fg\">.</span>unique<span class=\"ansi-blue-fg\">(</span>y<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/base.py</span> in <span class=\"ansi-cyan-fg\">_validate_data</span><span class=\"ansi-blue-fg\">(self, X, y, reset, validate_separately, **check_params)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    430</span>                 y <span class=\"ansi-blue-fg\">=</span> check_array<span class=\"ansi-blue-fg\">(</span>y<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>check_y_params<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    431</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 432</span><span class=\"ansi-red-fg\">                 </span>X<span class=\"ansi-blue-fg\">,</span> y <span class=\"ansi-blue-fg\">=</span> check_X_y<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> y<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>check_params<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    433</span>             out <span class=\"ansi-blue-fg\">=</span> X<span class=\"ansi-blue-fg\">,</span> y\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    434</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">inner_f</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                           FutureWarning)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         kwargs<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>k<span class=\"ansi-blue-fg\">:</span> arg <span class=\"ansi-green-fg\">for</span> k<span class=\"ansi-blue-fg\">,</span> arg <span class=\"ansi-green-fg\">in</span> zip<span class=\"ansi-blue-fg\">(</span>sig<span class=\"ansi-blue-fg\">.</span>parameters<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 73</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>     <span class=\"ansi-green-fg\">return</span> inner_f\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     75</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">check_X_y</span><span class=\"ansi-blue-fg\">(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    801</span>                     ensure_min_samples<span class=\"ansi-blue-fg\">=</span>ensure_min_samples<span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    802</span>                     ensure_min_features<span class=\"ansi-blue-fg\">=</span>ensure_min_features<span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 803</span><span class=\"ansi-red-fg\">                     estimator=estimator)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">    804</span>     <span class=\"ansi-green-fg\">if</span> multi_output<span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    805</span>         y = check_array(y, accept_sparse=&#39;csr&#39;, force_all_finite=True,\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">inner_f</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                           FutureWarning)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         kwargs<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>k<span class=\"ansi-blue-fg\">:</span> arg <span class=\"ansi-green-fg\">for</span> k<span class=\"ansi-blue-fg\">,</span> arg <span class=\"ansi-green-fg\">in</span> zip<span class=\"ansi-blue-fg\">(</span>sig<span class=\"ansi-blue-fg\">.</span>parameters<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 73</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>     <span class=\"ansi-green-fg\">return</span> inner_f\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     75</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">check_array</span><span class=\"ansi-blue-fg\">(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    597</span>                     array <span class=\"ansi-blue-fg\">=</span> array<span class=\"ansi-blue-fg\">.</span>astype<span class=\"ansi-blue-fg\">(</span>dtype<span class=\"ansi-blue-fg\">,</span> casting<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#34;unsafe&#34;</span><span class=\"ansi-blue-fg\">,</span> copy<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    598</span>                 <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 599</span><span class=\"ansi-red-fg\">                     </span>array <span class=\"ansi-blue-fg\">=</span> np<span class=\"ansi-blue-fg\">.</span>asarray<span class=\"ansi-blue-fg\">(</span>array<span class=\"ansi-blue-fg\">,</span> order<span class=\"ansi-blue-fg\">=</span>order<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">=</span>dtype<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    600</span>             <span class=\"ansi-green-fg\">except</span> ComplexWarning<span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    601</span>                 raise ValueError(&#34;Complex data not supported\\n&#34;\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/numpy/core/_asarray.py</span> in <span class=\"ansi-cyan-fg\">asarray</span><span class=\"ansi-blue-fg\">(a, dtype, order)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     83</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     84</span>     &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-fg\">---&gt; 85</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> array<span class=\"ansi-blue-fg\">(</span>a<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">,</span> copy<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span> order<span class=\"ansi-blue-fg\">=</span>order<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     86</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/pandas/core/generic.py</span> in <span class=\"ansi-cyan-fg\">__array__</span><span class=\"ansi-blue-fg\">(self, dtype)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1991</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1992</span>     <span class=\"ansi-green-fg\">def</span> __array__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">:</span> NpDtype <span class=\"ansi-blue-fg\">|</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> np<span class=\"ansi-blue-fg\">.</span>ndarray<span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1993</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> np<span class=\"ansi-blue-fg\">.</span>asarray<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_values<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">=</span>dtype<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1994</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1995</span>     def __array_wrap__(\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/numpy/core/_asarray.py</span> in <span class=\"ansi-cyan-fg\">asarray</span><span class=\"ansi-blue-fg\">(a, dtype, order)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     83</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     84</span>     &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-fg\">---&gt; 85</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> array<span class=\"ansi-blue-fg\">(</span>a<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">,</span> copy<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span> order<span class=\"ansi-blue-fg\">=</span>order<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     86</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n",
       "\n",
       "<span class=\"ansi-red-fg\">ValueError</span>: could not convert string to float: &#39;PC 17609&#39;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4371513980580996&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># execute search</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>result <span class=\"ansi-blue-fg\">=</span> search<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> Y<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> <span class=\"ansi-red-fg\"># summarize result</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;Best Score: %s&#39;</span> <span class=\"ansi-blue-fg\">%</span> result<span class=\"ansi-blue-fg\">.</span>best_score_<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;Best Hyperparameters: %s&#39;</span> <span class=\"ansi-blue-fg\">%</span> result<span class=\"ansi-blue-fg\">.</span>best_params_<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">inner_f</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                           FutureWarning)\n<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         kwargs<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>k<span class=\"ansi-blue-fg\">:</span> arg <span class=\"ansi-green-fg\">for</span> k<span class=\"ansi-blue-fg\">,</span> arg <span class=\"ansi-green-fg\">in</span> zip<span class=\"ansi-blue-fg\">(</span>sig<span class=\"ansi-blue-fg\">.</span>parameters<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 73</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>     <span class=\"ansi-green-fg\">return</span> inner_f\n<span class=\"ansi-green-intense-fg ansi-bold\">     75</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/model_selection/_search.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, X, y, groups, **fit_params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    763</span>             refit_start_time <span class=\"ansi-blue-fg\">=</span> time<span class=\"ansi-blue-fg\">.</span>time<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    764</span>             <span class=\"ansi-green-fg\">if</span> y <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 765</span><span class=\"ansi-red-fg\">                 </span>self<span class=\"ansi-blue-fg\">.</span>best_estimator_<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> y<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>fit_params<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    766</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    767</span>                 self<span class=\"ansi-blue-fg\">.</span>best_estimator_<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>fit_params<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, X, y, sample_weight)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1342</span>         X, y = self._validate_data(X, y, accept_sparse=&#39;csr&#39;, dtype=_dtype,\n<span class=\"ansi-green-intense-fg ansi-bold\">   1343</span>                                    order<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#34;C&#34;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">-&gt; 1344</span><span class=\"ansi-red-fg\">                                    accept_large_sparse=solver != &#39;liblinear&#39;)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1345</span>         check_classification_targets<span class=\"ansi-blue-fg\">(</span>y<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1346</span>         self<span class=\"ansi-blue-fg\">.</span>classes_ <span class=\"ansi-blue-fg\">=</span> np<span class=\"ansi-blue-fg\">.</span>unique<span class=\"ansi-blue-fg\">(</span>y<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/base.py</span> in <span class=\"ansi-cyan-fg\">_validate_data</span><span class=\"ansi-blue-fg\">(self, X, y, reset, validate_separately, **check_params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    430</span>                 y <span class=\"ansi-blue-fg\">=</span> check_array<span class=\"ansi-blue-fg\">(</span>y<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>check_y_params<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    431</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 432</span><span class=\"ansi-red-fg\">                 </span>X<span class=\"ansi-blue-fg\">,</span> y <span class=\"ansi-blue-fg\">=</span> check_X_y<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> y<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>check_params<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    433</span>             out <span class=\"ansi-blue-fg\">=</span> X<span class=\"ansi-blue-fg\">,</span> y\n<span class=\"ansi-green-intense-fg ansi-bold\">    434</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">inner_f</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                           FutureWarning)\n<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         kwargs<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>k<span class=\"ansi-blue-fg\">:</span> arg <span class=\"ansi-green-fg\">for</span> k<span class=\"ansi-blue-fg\">,</span> arg <span class=\"ansi-green-fg\">in</span> zip<span class=\"ansi-blue-fg\">(</span>sig<span class=\"ansi-blue-fg\">.</span>parameters<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 73</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>     <span class=\"ansi-green-fg\">return</span> inner_f\n<span class=\"ansi-green-intense-fg ansi-bold\">     75</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">check_X_y</span><span class=\"ansi-blue-fg\">(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    801</span>                     ensure_min_samples<span class=\"ansi-blue-fg\">=</span>ensure_min_samples<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    802</span>                     ensure_min_features<span class=\"ansi-blue-fg\">=</span>ensure_min_features<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">--&gt; 803</span><span class=\"ansi-red-fg\">                     estimator=estimator)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    804</span>     <span class=\"ansi-green-fg\">if</span> multi_output<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    805</span>         y = check_array(y, accept_sparse=&#39;csr&#39;, force_all_finite=True,\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">inner_f</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                           FutureWarning)\n<span class=\"ansi-green-intense-fg ansi-bold\">     72</span>         kwargs<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>k<span class=\"ansi-blue-fg\">:</span> arg <span class=\"ansi-green-fg\">for</span> k<span class=\"ansi-blue-fg\">,</span> arg <span class=\"ansi-green-fg\">in</span> zip<span class=\"ansi-blue-fg\">(</span>sig<span class=\"ansi-blue-fg\">.</span>parameters<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 73</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     74</span>     <span class=\"ansi-green-fg\">return</span> inner_f\n<span class=\"ansi-green-intense-fg ansi-bold\">     75</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/sklearn/utils/validation.py</span> in <span class=\"ansi-cyan-fg\">check_array</span><span class=\"ansi-blue-fg\">(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    597</span>                     array <span class=\"ansi-blue-fg\">=</span> array<span class=\"ansi-blue-fg\">.</span>astype<span class=\"ansi-blue-fg\">(</span>dtype<span class=\"ansi-blue-fg\">,</span> casting<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#34;unsafe&#34;</span><span class=\"ansi-blue-fg\">,</span> copy<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    598</span>                 <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 599</span><span class=\"ansi-red-fg\">                     </span>array <span class=\"ansi-blue-fg\">=</span> np<span class=\"ansi-blue-fg\">.</span>asarray<span class=\"ansi-blue-fg\">(</span>array<span class=\"ansi-blue-fg\">,</span> order<span class=\"ansi-blue-fg\">=</span>order<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">=</span>dtype<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    600</span>             <span class=\"ansi-green-fg\">except</span> ComplexWarning<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    601</span>                 raise ValueError(&#34;Complex data not supported\\n&#34;\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/numpy/core/_asarray.py</span> in <span class=\"ansi-cyan-fg\">asarray</span><span class=\"ansi-blue-fg\">(a, dtype, order)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     83</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     84</span>     &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">---&gt; 85</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> array<span class=\"ansi-blue-fg\">(</span>a<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">,</span> copy<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span> order<span class=\"ansi-blue-fg\">=</span>order<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     86</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/pandas/core/generic.py</span> in <span class=\"ansi-cyan-fg\">__array__</span><span class=\"ansi-blue-fg\">(self, dtype)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1991</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1992</span>     <span class=\"ansi-green-fg\">def</span> __array__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">:</span> NpDtype <span class=\"ansi-blue-fg\">|</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> np<span class=\"ansi-blue-fg\">.</span>ndarray<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1993</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> np<span class=\"ansi-blue-fg\">.</span>asarray<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_values<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">=</span>dtype<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1994</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1995</span>     def __array_wrap__(\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/numpy/core/_asarray.py</span> in <span class=\"ansi-cyan-fg\">asarray</span><span class=\"ansi-blue-fg\">(a, dtype, order)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     83</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     84</span>     &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">---&gt; 85</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> array<span class=\"ansi-blue-fg\">(</span>a<span class=\"ansi-blue-fg\">,</span> dtype<span class=\"ansi-blue-fg\">,</span> copy<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">,</span> order<span class=\"ansi-blue-fg\">=</span>order<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     86</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n\n<span class=\"ansi-red-fg\">ValueError</span>: could not convert string to float: &#39;PC 17609&#39;</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">ValueError</span>: could not convert string to float: &#39;PC 17609&#39;",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# execute search\n",
    "result = search.fit(X, Y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa31831d-e024-43a6-8b37-85a17645598c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88d20b5b-07d5-45a7-95c8-42a963db9eed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a61cccf-dfd8-49b2-9410-f53f8c74111b",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.002603,
     "end_time": "2023-02-05T05:59:39.720723",
     "exception": false,
     "start_time": "2023-02-05T05:59:39.718120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ajustando XGBoost com Optuna\n",
    "\n",
    "Neste exemplo, os hiperparâmetros `learning_rate`, `max_depth`, `n_estimators` e `min_child_weight` são ajustados usando a biblioteca Optuna. A função objetivo é definida para retornar a precisão negativa no conjunto de teste, pois Optuna minimiza a função objetivo. A função `study.optimize` é usada para executar o ajuste do hiperparâmetro, com `n_trials` especificando o número de tentativas a serem executadas. O desempenho final do classificador sintonizado é avaliado no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb9c7853-1939-4843-8d7e-69286fed4053",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-02-05T05:59:39.728911Z",
     "iopub.status.busy": "2023-02-05T05:59:39.728373Z",
     "iopub.status.idle": "2023-02-05T06:03:54.733010Z",
     "shell.execute_reply": "2023-02-05T06:03:54.731347Z"
    },
    "papermill": {
     "duration": 255.013475,
     "end_time": "2023-02-05T06:03:54.737031",
     "exception": false,
     "start_time": "2023-02-05T05:59:39.723556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 7)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    \n",
    "    # Create an XGBoost classifier\n",
    "    clf = XGBClassifier(\n",
    "        learning_rate=learning_rate, \n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators, \n",
    "        min_child_weight=min_child_weight\n",
    "    )\n",
    "    \n",
    "    # Train the classifier and calculate the accuracy on the validation set\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    return 1.0 - score\n",
    "\n",
    "# Use Optuna to tune the hyperparameters\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best score\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best score: \", 1.0 - study.best_value)\n",
    "\n",
    "# Train the classifier with the best hyperparameters on the full training set\n",
    "best_params = study.best_params\n",
    "clf = XGBClassifier(\n",
    "    learning_rate=best_params[\"learning_rate\"], \n",
    "    max_depth=best_params[\"max_depth\"],\n",
    "    n_estimators=best_params[\"n_estimators\"], \n",
    "    min_child_weight=best_params[\"min_child_weight\"]\n",
    ")\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Evaluate the tuned classifier on the test set\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"Test set accuracy: \", score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ac8065e-f6c9-45c7-acac-63e42ee97d52",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.00903,
     "end_time": "2023-02-05T06:03:54.755719",
     "exception": false,
     "start_time": "2023-02-05T06:03:54.746689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ajustando Random Forest com Optuna\n",
    "\n",
    "Neste exemplo, os hiperparâmetros `n_estimators`, `max_depth`, `min_samples_split` e `min_samples_leaf` são ajustados usando a biblioteca Optuna. A função objetivo é definida para retornar a precisão negativa no conjunto de teste, pois Optuna minimiza a função objetivo. A função `study.optimize` é usada para executar o ajuste do hiperparâmetro, com `n_trials` especificando o número de tentativas a serem executadas. O desempenho final do classificador sintonizado é avaliado em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e8b1c0c-9896-4e35-b5ac-0f470e45925e",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-02-05T06:03:54.778465Z",
     "iopub.status.busy": "2023-02-05T06:03:54.777149Z",
     "iopub.status.idle": "2023-02-05T06:06:01.563678Z",
     "shell.execute_reply": "2023-02-05T06:06:01.562536Z"
    },
    "papermill": {
     "duration": 126.801533,
     "end_time": "2023-02-05T06:06:01.566578",
     "exception": false,
     "start_time": "2023-02-05T06:03:54.765045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 7)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 5)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 5)\n",
    "    \n",
    "    # Create a random forest classifier\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split, \n",
    "        min_samples_leaf=min_samples_leaf\n",
    "    )\n",
    "    \n",
    "    # Train the classifier and calculate the accuracy on the validation set\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    return 1.0 - score\n",
    "\n",
    "# Use Optuna to tune the hyperparameters\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best score\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best score: \", 1.0 - study.best_value)\n",
    "\n",
    "# Train the classifier with the best hyperparameters on the full training set\n",
    "best_params = study.best_params\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=best_params[\"n_estimators\"], \n",
    "    max_depth=best_params[\"max_depth\"],\n",
    "    min_samples_split=best_params[\"min_samples_split\"], \n",
    "    min_samples_leaf=best_params[\"min_samples_leaf\"]\n",
    ")\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Evaluate the tuned classifier on the test set\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"Test set accuracy: \", score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f31fdc5a-3c22-4956-bc3e-fe7794f3c34a",
     "showTitle": false,
     "title": ""
    },
    "papermill": {
     "duration": 0.015439,
     "end_time": "2023-02-05T06:06:01.598538",
     "exception": false,
     "start_time": "2023-02-05T06:06:01.583099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pesquisa Aleatória\n",
    "\n",
    ">- Os valores de hiperparâmetros são selecionados por sorteios independentes (aleatórios) da distribuição uniforme do espaço de hiperparâmetros. A Pesquisa aleatória seleciona as combinações de valores de hiperparâmetros aleatoriamente de todas as combinações possíveis, dado um espaço de hiperparâmetros.\n",
    "\n",
    "---\n",
    "\n",
    "## Pesquisa Aleatória vs Pesquisa em Grade\n",
    ">- Alguns parâmetros afetam muito o desempenho e outros não (Low Effective Dimension).\n",
    "\n",
    "| Pesquisa Aleatória | Pesquisa em grade |\n",
    "\n",
    "|:------------------------------------------------ -------------------|------------------------------ ----------:|\n",
    "\n",
    "| Permite a exploração de mais dimensões de parâmetros importantes | Perder tempo explorando dimensões não importantes |\n",
    "\n",
    "| Selecione valores de uma distribuição de valores de parâmetros | Os parâmetros são definidos manualmente |\n",
    "\n",
    "| Bom para parâmetros contínuos | Bom para parâmetros discretos |\n",
    "\n",
    "---\n",
    "\n",
    "## Considerações\n",
    ">- Escolhemos um orçamento (computacional) independentemente do número de parâmetros e valores possíveis.\n",
    ">- Adicionar parâmetros que não influenciam o desempenho não diminui a eficiência da pesquisa (se forem permitidas iterações suficientes).\n",
    ">- Importante especificar uma distribuição contínua do hiperparâmetro para aproveitar ao máximo a randomização."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bb0c766-ebe9-427e-8eea-7881ec46055f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "**References:** \n",
    "\n",
    "https://www.kaggle.com/code/willkoehrsen/intro-to-model-tuning-grid-and-random-search/notebook \n",
    "\n",
    "https://www.kaggle.com/code/faressayah/hyperparameter-optimization-for-machine-learning \n",
    "\n",
    "https://github.com/optuna/optuna-examples/blob/main/xgboost/xgboost_simple.py"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Class_15_optimization",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 392.626621,
   "end_time": "2023-02-05T06:06:02.741994",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-05T05:59:30.115373",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
