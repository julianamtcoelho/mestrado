{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5799c52-51d7-4f39-b71d-c311ae8dae64",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Outliers\n",
    "\n",
    "An outlier is a data point which is significantly different from the remaining data. \"An outlier is an observation which deviates so much from the other observations as to arouse suspicions that it was generated by a different mechanism.\" [D. Hawkins. Identification of Outliers, Chapman and Hall , 1980.]\n",
    "\n",
    "\n",
    "### Should outliers be removed?\n",
    "\n",
    "Depending on the context, outliers either deserve special attention or should be completely ignored. Take the example of revenue forecasting: if unusual spikes of revenue are observed, it's probably a good idea to pay extra attention to them and figure out what caused the spike. In the same way, an unusual transaction on a credit card is usually a sign of fraudulent activity, which is what the credit card issuer wants to prevent. So in instances like these, it is useful to look for and investigate further outlier values.\n",
    "\n",
    "If outliers are however, introduced due to mechanical error, measurement error or anything else that can't be generalised, it is a good idea to remove these outliers before feeding the data to the modeling algorithm. Why? Because some algorithms are sensitive to outliers. \n",
    "\n",
    "\n",
    "### Which machine learning models are sensitive to outliers?\n",
    "\n",
    "Some machine learning models are more sensitive to outliers than others. For instance, AdaBoost may treat outliers as \"hard\" cases and put tremendous weights on outliers, therefore producing a model with bad generalisation.\n",
    "\n",
    "Linear models, in particular Linear Regression, can be also sensitive to outliers.\n",
    "\n",
    "Decision trees tend to ignore the presence of outliers when creating the branches of their trees. Typically, trees make decisions by asking if variable x >= a certain value, and therefore the outlier will fall on each side of the branch, but it will be treated equally than the remaining values, regardless of its magnitude.\n",
    "\n",
    "A recent research article suggests that Neural Networks could also be sensitive to outliers, provided the number of outliers is high and the deviation is also high. I would argue that if the number of outliers is high (>15% as suggested in the article), then they are no longer outliers, and rather a fair representation of that variable. A link to this article can be found in the \"Additional reading resources\" lecture within this section of the course.\n",
    "\n",
    "\n",
    "### How can outliers be identified?\n",
    "\n",
    "Outlier analysis and anomaly detection are a huge field of research devoted to optimise methods and create new algorithms to reliably identify outliers. There are a huge number of ways optimised to detect outliers in different situations. These are mostly targeted to identify outliers when those are the observations that we indeed want to focus on, for example for fraudulent credit card activity.\n",
    "\n",
    "In this course, however, I will focus on identifying those outliers introduced by mechanical or measurement error. Those outliers that are indeed a rare case in the population, and that could be ignored. I will show how to identify those outliers, so that in later sections of the course, we can learn how to pre-process them before using the variable to train machine learning algorithms.\n",
    "\n",
    "\n",
    "### Extreme Value Analysis\n",
    "\n",
    "The most basic form of outlier detection is **Extreme Value Analysis** of 1-dimensional data. The key for this method is to determine the statistical tails of the underlying distribution of the variable, and then find the values that sit at the very end of the tails.\n",
    "\n",
    "If the the variable is Normally distributed (Gaussian), then the values that lie outside the mean plus or minus 3 times the standard deviation of the variable are considered outliers.\n",
    "\n",
    "- outliers = mean +/- 3* std\n",
    "\n",
    "\n",
    "If the variable is skewed distributed, a general approach is to calculate the quantiles, and then the inter-quantile range (IQR), as follows:\n",
    "\n",
    "- IQR = 75th quantile - 25th quantile\n",
    "\n",
    "An outlier will sit outside the following upper and lower boundaries:\n",
    "\n",
    "- Upper boundary = 75th quantile + (IQR * 1.5)\n",
    "\n",
    "- Lower boundary = 25th quantile - (IQR * 1.5)\n",
    "\n",
    "or for extreme cases:\n",
    "\n",
    "- Upper boundary = 75th quantile + (IQR * 3)\n",
    "\n",
    "- Lower boundary = 25th quantile - (IQR * 3)\n",
    "\n",
    "\n",
    "\n",
    "## Datasets for this notebook: \n",
    "\n",
    "In this declass, we will use the House Prices and Titanic datasets.\n",
    "\n",
    "We will also use a dataset included in Scikit-learn: Boston house prices dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b46d88b6-57fc-40e1-a726-3d9b50e3664d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## In this class\n",
    "\n",
    "We will:\n",
    "\n",
    "- Identify outliers using complete case analysis in Normally distributed variables.\n",
    "- Identify outliers using complete case analysis in skewed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8213c970-8ec6-4ccc-91d0-4d648bd94e06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U seaborn\n",
    "%pip install -U feature-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c8c276-cce6-4b43-b29b-36578d653ba7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# print information for boston dataset\n",
    "from sklearn.datasets import load_boston\n",
    "print(load_boston().DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "147cdea1-1d36-4ffe-abbc-0785ce1e0070",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from feature_engine.outliers import Winsorizer\n",
    "\n",
    "# for Q-Q plots\n",
    "import scipy.stats as stats\n",
    "\n",
    "# boston house dataset for the demo\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab227a27-39dc-43f9-aaae-650ed6133e67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load the boston dataset from sklearn\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "# create a dataframe with the independent variables we will use only 3 of the total variables for this demo\n",
    "\n",
    "boston = pd.DataFrame(boston_dataset.data,\n",
    "                      columns=boston_dataset.feature_names)[[\n",
    "                          'RM', 'LSTAT', 'CRIM'\n",
    "                      ]]\n",
    "\n",
    "\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a98e177-1a4e-48ca-b9f8-2559ed130f6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load the titanic dataset\n",
    "\n",
    "titanic = pd.read_csv('/dbfs/FileStore/CDS2023/titanic.csv', usecols=['age', 'fare'])\n",
    "\n",
    "# The variables age and fare have missing values, I will remove them for this demo\n",
    "titanic.dropna(subset=['age', 'fare'], inplace=True)\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c01ee3c-d143-43ad-b130-e77bc6ed742d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Identify variable distribution\n",
    "\n",
    "In Normally distributed variables, outliers are those values that lie beyond the mean plus or minus 3 times the standard deviation. If the variables are skewed however, we find outliers using the inter-quantile range. In order to decide which method to utilise to detect outliers, we first need to know the distribution of the variable.\n",
    "\n",
    "We can use histograms and Q-Q plots to determine if the variable is normally distributed. We can also use boxplots to directly visualise the outliers. Boxplots are a standard way of displaying the distribution of a variable utilising the first quartile, the median, the third quartile and the whiskers.\n",
    "\n",
    "Looking at a boxplot, you can easily identify:\n",
    "\n",
    "- The median, indicated by the line within the box.\n",
    "- The inter-quantile range (IQR), the box itself.\n",
    "- The quantiles, 25th (Q1) is the lower and 75th (Q3) the upper end of the box.\n",
    "- The wiskers, which extend to: \n",
    "  -- top whisker: Q3 + 1.5 x IQR\n",
    "  -- bottom whisker: Q1 -1.5 x IQR\n",
    "\n",
    "Any value sitting outside the whiskers is considered an outlier. Let's look at the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18e435f4-f4e0-43e6-a676-b8b23fc1fec5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to create histogram, Q-Q plot and boxplot\n",
    "\n",
    "\n",
    "def diagnostic_plots(df, variable):\n",
    "    # function takes a dataframe (df) and the variable of interest as arguments\n",
    "\n",
    "    # define figure size\n",
    "    plt.figure(figsize=(16, 4))\n",
    "\n",
    "    # histogram\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.histplot(df[variable], bins=30)\n",
    "    plt.title('Histogram')\n",
    "\n",
    "    # Q-Q plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    stats.probplot(df[variable], dist=\"norm\", plot=plt)\n",
    "    plt.ylabel('Actual quantiles')\n",
    "\n",
    "    # boxplot\n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.boxplot(y=df[variable])\n",
    "    plt.title('Boxplot')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8765c9a-8225-4791-be2a-3725b1002817",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Normally distributed variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5df9a66-387b-4b33-9b22-6f32677bb330",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's start with the variable RM from the Boston house dataset. RM is the average number of rooms per dwelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cb83630-64ce-4b6f-9b3d-e81f15f99f26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diagnostic_plots(boston, 'RM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1111957b-63aa-4907-b151-abae2cf10f73",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "From the histogram and the Q-Q plot, we see that the variable rm approximates a Gaussian distribution quite well. In the boxplot, we see that the variable could have outliers, as there are many dots sitting outside the whiskers, at both tails of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8acaf99-15b3-42bf-b5e7-7f9215e68100",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's inspect now the variable Age from the titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5826e107-e7f1-4e4a-a4f6-1c1ced7b41a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diagnostic_plots(titanic, 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "581e8e2d-2dc3-4643-9dcb-e08a3e563652",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "From the histogram and the Q-Q plot, we see that the variable approximates fairly well a Gaussian distribution. There is a deviation from the distribution towards the smaller values of age. In the boxplot, we can see that the variable could have outliers, as there are many dots sitting outside the whiskers, at the right end of the distribution (top whisker in the boxplot)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b331766b-0c75-4301-8a60-ab24a012b541",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Skewed variables\n",
    "Let's use the variable LSTAT from the Boston house dataset. LSTAT is the % lower status of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ab24757-4bff-44b4-94f0-b278ed46d33f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diagnostic_plots(boston, 'LSTAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "160da9b2-8b65-499e-8790-64a0c45da8bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "LSTAT is not normally distributed, it is skewed with a tail to the right. According to the boxplot, there are some outliers at the right end of the distribution of the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05b3516b-1fe0-4608-b562-2506ce039ce1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let´s analyze variable CRIM from the Boston house dataset. CRIM is the per capita crime rate by town."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05cd00f1-b6b3-42f9-b97f-4b5053768d20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diagnostic_plots(boston, 'CRIM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ee446d3-8cf2-4012-8ae4-a9903128c3bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "CRIM is heavily skewed, with a tail to the right. There seems to be quite a few outliers as well at the right end of the distribution, according to the boxplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62c5ab52-06c1-4b35-a74c-2879b14fc787",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let´s analyze variable Fare from the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7a5c017-171a-4598-a4be-a63ad40a6934",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diagnostic_plots(titanic, 'fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5903f43b-64a1-4e27-bdcd-f89d07bd87f4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Fare is also very skewed, and shows some unusual values at the right end of its distribution.\n",
    "\n",
    "In the next cells We will identify outliers using the mean and the standard deviation for the variables RM and Age from the boston and titanic datasets, respectively. Then we will use the inter-quantile range to identify outliers for the variables LSTAT, CRIM and Fare from the boston and titanic datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80ad74c2-f02d-4cac-a51a-c1cb4fd3d743",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Outlier detection for Normally distributed variables\n",
    "Function to find upper and lower boundaries for normally distributed variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "990ad4d5-0f82-4426-8d2c-e0a312579839",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def find_normal_boundaries(df, variable):\n",
    "\n",
    "    # Calculate the boundaries outside which sit the outliers for a Gaussian distribution\n",
    "\n",
    "    upper_boundary = df[variable].mean() + 3 * df[variable].std()\n",
    "    lower_boundary = df[variable].mean() - 3 * df[variable].std()\n",
    "\n",
    "    return upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6145e57f-f294-4ed2-8466-95e8809bd9c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate boundaries for RM\n",
    "upper_boundary, lower_boundary = find_normal_boundaries(boston, 'RM')\n",
    "upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3151e88c-43b0-4d10-a879-835a993b9d29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "From the above we conclude that values bigger than 8.4 or smaller than 4.2 occur very rarely for the variable RM. Therefore, we can consider them outliers.\n",
    "\n",
    "Let's inspect the number and percentage of outliers for RM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f3fda7a-489a-409a-9e26-c94f26594844",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('total number of houses: {}'.format(len(boston)))\n",
    "\n",
    "print('houses with more than 8.4 rooms (right end outliers): {}'.format(\n",
    "    len(boston[boston['RM'] > upper_boundary])))\n",
    "\n",
    "print('houses with less than 4.2 rooms (left end outliers: {}'.format(\n",
    "    len(boston[boston['RM'] < lower_boundary])))\n",
    "print()\n",
    "print('% right end outliers: {}'.format(\n",
    "    len(boston[boston['RM'] > upper_boundary]) / len(boston)))\n",
    "\n",
    "print('% left end outliers: {}'.format(\n",
    "    len(boston[boston['RM'] < lower_boundary]) / len(boston)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "992ecb56-eb0b-49b1-a8fb-c2cfe9e26114",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Using Extreme Value Analysis we identified outliers at both ends of the distribution of RM. The percentage of outliers is small (1.4% considering the 2 tails together), which makes sense, because we are finding precisely outliers. That is, rare values, rare occurrences.\n",
    "\n",
    "Let's move on to Age in the titanic dataset. Let's calculate boundaries for Age in the titanic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ba6293b-49db-40fd-a220-ac0fbae1a4f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "upper_boundary, lower_boundary = find_normal_boundaries(titanic, 'age')\n",
    "upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a31c1b2-e536-4560-a0d4-50517c94c11e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The upper boundary is 73 years, which means that passengers older than 73 were very few, if any, in the titanic. The lower boundary is negative. Because negative age does not exist, it only makes sense to look for outliers utilising the upper boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "984d7989-60a2-4bc5-9438-00794264bab6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lets look at the number and percentage of outliers\n",
    "\n",
    "print('total passengers: {}'.format(len(titanic)))\n",
    "\n",
    "print('passengers older than 73: {}'.format(\n",
    "    len(titanic[titanic['age'] > upper_boundary])))\n",
    "print()\n",
    "print('% of passengers older than 73: {}'.format(\n",
    "    len(titanic[titanic['age'] > upper_boundary]) / len(titanic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b1ab03d-b50b-49f7-afb0-9a03ebdd6a16",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "There were 2 passengers older than 73 on board of the titanic, which could be considered outliers, as the majority of the population where much younger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d08e0d7-b4e3-4f35-a966-2ddd9660577e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Outlier detection for skewed variables\n",
    "Function to find upper and lower boundaries for skewed distributed variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e9f0500-f710-4345-b51e-f4d75f730bfd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def find_skewed_boundaries(df, variable, distance):\n",
    "\n",
    "    # Let's calculate the boundaries outside which sit the outliers\n",
    "    # for skewed distributions\n",
    "\n",
    "    # distance passed as an argument, gives us the option to\n",
    "    # estimate 1.5 times or 3 times the IQR to calculate\n",
    "    # the boundaries.\n",
    "\n",
    "    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n",
    "\n",
    "    lower_boundary = df[variable].quantile(0.25) - (IQR * distance)\n",
    "    upper_boundary = df[variable].quantile(0.75) + (IQR * distance)\n",
    "\n",
    "    return upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba3a9623-a9cb-4c75-9da0-e180f09c7ba2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Looking for outliers in LSTAT in the Boston house dataset, using the interquantile proximity rule (IQR * 1.5, the standard metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c53fbc5-abce-4144-8a12-4956657a0789",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "upper_boundary, lower_boundary = find_skewed_boundaries(boston, 'LSTAT', 1.5)\n",
    "upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "006870e7-26dc-47b8-aa3a-6ad2c0432c27",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's look at the number and percentage of outliers for LSTAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "705ce43a-e3d4-4bf6-b6c1-4177fac6f750",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('total houses: {}'.format(len(boston)))\n",
    "\n",
    "print('houses with LSTAT bigger than 32: {}'.format(\n",
    "    len(boston[boston['LSTAT'] > upper_boundary])))\n",
    "print()\n",
    "print('% houses with LSTAT bigger than 32: {}'.format(\n",
    "    len(boston[boston['LSTAT'] > upper_boundary])/len(boston)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8e766c0-e5ca-4b1f-9b88-86b88defc3d1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The upper boundary shows a value of ~32. The lower boundary is negative, however the variable LSTAT does not take negative values. So to calculate the outliers for LSTAT we only use the upper boundary. This coincides with what we observed in the boxplot earlier in the notebook. Outliers sit only at the right tail of LSTAT's distribution.\n",
    "\n",
    "We observe 7 houses, 1.3 % of the dataset, with extremely high values for LSTAT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0b17036-10a4-4f91-853c-31a588b0e847",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's look for outliers, using the interquantile proximity rule (IQR * 3), now we are looking for extremely high values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3d65b7d-88a2-459a-bc83-13e2d80214dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "upper_boundary, lower_boundary = find_skewed_boundaries(boston, 'CRIM', 3)\n",
    "upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "647082cf-5aa0-4c23-b967-572341719b6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's look at the number and percentage of outliers for CRIM\n",
    "\n",
    "print('total houses: {}'.format(len(boston)))\n",
    "\n",
    "print('houses with CRIM bigger than 14: {}'.format(\n",
    "    len(boston[boston['CRIM'] > upper_boundary])))\n",
    "print()\n",
    "print('% houses with CRIM bigger than 14s: {}'.format(\n",
    "    len(boston[boston['CRIM'] > upper_boundary]) / len(boston)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c049e9b-ef8c-467d-9e6e-926cbfd35618",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "When using the 3  times inter-quantile range to find outliers, we find that ~6% of the houses show unusually high crime rate areas. For CRIM as well, the lower boundary is negative, so it only makes sense to use the upper boundary to calculate outliers, as the variable takes only positive values. This coincides with what we observed in CRIM's boxplot earlier in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7359d3e9-db62-4fc2-90ec-b7023df19578",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# finally, identify outliers in Fare in the Titanic dataset. I will look again for extreme values, using IQR * 3\n",
    "\n",
    "upper_boundary, lower_boundary = find_skewed_boundaries(titanic, 'fare', 3)\n",
    "upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5f32233-cac7-4956-af52-06308cdc40be",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's look at the number and percentage of passengers who paid extremely high Fares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9030022e-9ff6-45a6-8672-8723e40d51b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('total passengers: {}'.format(len(titanic)))\n",
    "\n",
    "print('passengers who paid more than 117: {}'.format(\n",
    "    len(titanic[titanic['fare'] > upper_boundary])))\n",
    "print()\n",
    "print('% passengers who paid more than 117: {}'.format(\n",
    "    len(titanic[titanic['fare'] > upper_boundary])/len(titanic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0b10d07-d306-4a82-9ff4-00c3bab0af3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "For Fare, as well as for all the other variables in this notebook which show a tail to the right, the lower boundary is negative. So we will use the upper boundary to determine the outliers. We observe that 6% of the values of the dataset fall above the boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d9642fa-30d1-403c-bff3-dde6c70c5e56",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#How can we deal with outliers?\n",
    "## Outlier Engineering\n",
    "\n",
    "### How can we pre-process outliers?\n",
    "\n",
    "- Trimming: remove the outliers from our dataset\n",
    "- Treat outliers as missing data, and proceed with any missing data imputation technique\n",
    "- Discrestisation: outliers are placed in border bins together with higher or lower values of the distribution\n",
    "- Censoring: capping the variable distribution at a max and / or minimum value\n",
    "\n",
    "**Censoring** is also known as:\n",
    "\n",
    "- top and bottom coding\n",
    "- winsorization\n",
    "- capping\n",
    "\n",
    "\n",
    "## Trimming or truncation\n",
    "\n",
    "Trimming, also known as truncation, involves removing the outliers from the dataset. We only need to decide on a metric to determine outliers. As we saw in section 3, this can be the Gaussian approximation for normally distributed variables or the inter-quantile range proximity rule for skewed variables.\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- quick\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- outliers for one variable could contain useful information in the other variables\n",
    "- if there are outliers across many variables, we could remove a big chunk of dataset\n",
    "\n",
    "## Important\n",
    "\n",
    "Outliers should be detected AND **removed ONLY** from the training set, and NOT from the test set.\n",
    "\n",
    "So we should first divide our data set into train and tests, and remove outliers in the train set, but keep those in the test set, and measure how well our model is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "652c863b-8d1c-4d98-acbe-a3c9262db359",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As we seen before, in the Boston dataset, there are outliers in some variables such as RM, LSTAT, CRIM. \n",
    "\n",
    "### 1 - First, let's use the functions we saw before to find the limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29dd7ffa-3915-4356-95ad-3c79bc7cf5aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Exercise:** Find the limits for RM, LSTAT and CRIM (named them variable_upper_limit and variable_lower_limit )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8ee3571-c20f-4a10-ac23-76f8c7a1eb52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09213792-3711-4eb2-a14e-1c3b24805ac3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2 - Let's flag the outliers in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1bfc8bb-a833-41fb-b201-fc6d650dd21c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outliers_RM = np.where(boston['RM'] > RM_upper_limit, True,\n",
    "                       np.where(boston['RM'] < RM_lower_limit, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3050ee9e-8b88-4ba3-a026-9f4d0a0a6af0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outliers_LSTAT = np.where(boston['LSTAT'] > LSTAT_upper_limit, True,\n",
    "                       np.where(boston['LSTAT'] < LSTAT_lower_limit, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4885c434-c4bc-43d3-8a1a-1f2cacf68e5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outliers_CRIM = np.where(boston['CRIM'] > CRIM_upper_limit, True,\n",
    "                       np.where(boston['CRIM'] < CRIM_lower_limit, True, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a6f6751-fc8c-4ce3-85b9-316d998f85fd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3 - Let's trimm the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d6af827-f83c-48fc-b6fe-1ffef0c6bca3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "boston_trimmed = boston.loc[~(outliers_RM + outliers_LSTAT + outliers_CRIM), ]\n",
    "\n",
    "boston.shape, boston_trimmed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fc3dcbb-8459-4c4b-9aa0-b65f7cb826d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can see that using trimming, we removed almost 100 rows, from a dataset of 500 rows, this is about 20% of the data was removed. This is mostly why, we do not tend to use trimming much in machine learning. But if only a few variables present a tiny proportion of outliers, trimming could work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7214a0a-95d0-44d4-b3b2-d609c5f5e53f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's explore outliers in the trimmed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b808a77-e926-4ade-ae4c-13486d855343",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diagnostic_plots(boston_trimmed, 'RM')\n",
    "diagnostic_plots(boston_trimmed, 'LSTAT')\n",
    "diagnostic_plots(boston_trimmed, 'CRIM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efc02d58-ef96-4d88-820f-2c75d7c6f6d6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "For LSTAT and CRIM, we still see many outliers. When we remove data points from our dataset, all the parameters of the distribution are re-calculated, those are the mean, quantiles and inter-quantile range, therefore, in the new -trimmed- variable, values that before were not considered outliers, now are.\n",
    "\n",
    "This is an unwanted characteristic of this way of coping with outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd11ebb5-fdaf-45c8-bd94-c2dc2aa50188",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Let's see another method to deal with outliers\n",
    "## Censoring or Capping.\n",
    "\n",
    "**Censoring**, or **capping**, means capping the maximum and /or minimum of a distribution at an arbitrary value. On other words, values bigger or smaller than the arbitrarily determined ones are **censored**.\n",
    "\n",
    "Capping can be done at both tails, or just one of the tails, depending on the variable and the user.\n",
    "\n",
    "Check [pydata](https://www.youtube.com/watch?v=KHGGlozsRtA) for an example of capping used in a finance company.\n",
    "\n",
    "The numbers at which to cap the distribution can be determined:\n",
    "\n",
    "- arbitrarily\n",
    "- using the inter-quantal range proximity rule\n",
    "- using the gaussian approximation\n",
    "- using quantiles\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- does not remove data\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- distorts the distributions of the variables\n",
    "- distorts the relationships among variables\n",
    "\n",
    "## Important\n",
    "\n",
    "When doing capping, we tend to cap values both in train and test set. It is important to remember that the capping values MUST be derived from the train set. And then use those same values to cap the variables in the test set\n",
    "\n",
    "I will not do that in this class, but please keep that in mind when setting up your pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b582f30c-e851-43e3-861d-6eac94a3bdd1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Let's create the capper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89903b4b-1e99-456f-b05d-404be6fac9e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "windsoriser = Winsorizer(capping_method='quantiles', # choose from iqr, gaussian or quantiles\n",
    "                          tail='both', # cap left, right or both tails \n",
    "                          fold=0.05,\n",
    "                          variables=['RM', 'LSTAT', 'CRIM'])\n",
    "\n",
    "windsoriser.fit(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30361564-d944-4623-af3d-19588ef9e516",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "boston_t = windsoriser.transform(boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bc93c40-4b0e-4e35-bdb6-2a640c84cb99",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's compare the outliers before and after the censoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d6df075-ee0d-46b3-838a-894a13acb2fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diagnostic_plots(boston, 'RM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bed321bd-d0ef-48b9-a543-270595033b01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diagnostic_plots(boston_t, 'RM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1d0ac8c-ba05-412b-b646-c859162bf7c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can inspect the mininum and maximun caps for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b98bc76-b3dc-4c67-b88d-d5058356bf88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "windsoriser.right_tail_caps_\n",
    "windsoriser.left_tail_caps_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86f1db73-5d02-4692-b3c7-1016d2da1269",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Authors:** Juliana da Mota Coelho, Camila Mizokami\n",
    "\n",
    "**References:**\n",
    "\n",
    "https://ndgigliotti.medium.com/trimming-vs-winsorizing-outliers-e5cae0bf22cb \n",
    "\n",
    "https://feature-engine.trainindata.com/en/1.0.x/outliers/Winsorizer.html \n",
    "\n",
    "https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623 \n",
    "\n",
    "https://feature-engine.readthedocs.io/en/latest/outliers/OutlierTrimmer.html"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Class_4_Outliers",
   "notebookOrigID": 1875884500805706,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
