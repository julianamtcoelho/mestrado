{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aada49a-70be-498b-b588-4c83e66d0329",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Valores ausentes\n",
    "\n",
    "Dados ausentes ou valores ausentes ocorrem quando __nenhum dado__ / __nenhum valor__ é armazenado para determinadas observações dentro de uma variável.\n",
    "\n",
    "Dados incompletos são um problema inevitável na maioria das fontes de dados e podem ter um impacto significativo nas conclusões que podem ser derivadas dos dados.\n",
    "\n",
    "### Por que faltam dados?\n",
    "\n",
    "A origem dos dados ausentes pode ser muito diferente. Estes são apenas alguns exemplos:\n",
    "\n",
    "- Um valor está faltando porque foi esquecido, perdido ou não foi armazenado corretamente\n",
    "- Para uma determinada observação, o valor não existe\n",
    "- O valor não pode ser conhecido ou identificado\n",
    "\n",
    "Em muitas organizações, as informações são coletadas em um formulário por uma pessoa que fala com um cliente ao telefone ou, alternativamente, por clientes que preenchem formulários online. Muitas vezes, a pessoa que insere os dados não preenche todos os campos do formulário. Muitos dos campos não são obrigatórios, o que pode levar a valores omissos.\n",
    "\n",
    "Os motivos da omissão da informação podem variar: talvez a pessoa não queira divulgar alguma informação, por exemplo rendimentos, ou não saiba a resposta, ou a resposta não se aplica a uma determinada circunstância, ou pelo contrário, a pessoa na organização quer poupar algum tempo ao cliente e, portanto, omite fazer perguntas que eles acham que não são tão relevantes.\n",
    "\n",
    "Existem outros casos em que o valor para uma determinada variável não existe. Por exemplo, na variável 'dívida total como porcentagem da renda total' (muito comum em dados financeiros), se a pessoa não tiver renda, então a porcentagem total de 0 não existe e, portanto, será um valor ausente.\n",
    "\n",
    "É importante entender **como os dados ausentes são introduzidos no conjunto de dados**, ou seja, os **mecanismos** pelos quais as informações ausentes são introduzidas em um conjunto de dados. Dependendo do mecanismo, podemos optar por processar os valores ausentes de maneira diferente. Além disso, ao conhecer a fonte dos dados perdidos, podemos optar por tomar medidas para controlar essa fonte e diminuir a quantidade de informações perdidas durante a coleta de dados.\n",
    "\n",
    "\n",
    "### Mecanismos de dados ausentes\n",
    "\n",
    "Existem 3 mecanismos que levam a dados perdidos, 2 deles envolvem dados perdidos aleatoriamente ou quase aleatoriamente, e o terceiro envolve uma perda sistemática de dados.\n",
    "\n",
    "#### Faltando completamente ao acaso, MCAR:\n",
    "\n",
    "Uma variável está faltando completamente ao acaso (MCAR) se a probabilidade de faltar é a mesma para todas as observações.\n",
    "Quando os dados são MCAR, não há absolutamente nenhuma relação entre os dados ausentes e quaisquer outros valores, observados ou ausentes, no conjunto de dados. Em outras palavras, esses pontos de dados ausentes são um subconjunto aleatório dos dados. Não há nada sistemático acontecendo que torne alguns dados mais prováveis de serem perdidos do que outros. Se os valores das observações estiverem ausentes completamente ao acaso, desconsiderar esses casos não influenciaria as inferências feitas.\n",
    "\n",
    "\n",
    "#### Faltando ao acaso, MAR:\n",
    "\n",
    "O MAR ocorre quando há uma relação entre a propensão de valores faltantes e os dados observados. Em outras palavras, a probabilidade de uma observação estar ausente depende das informações disponíveis (ou seja, outras variáveis no conjunto de dados). Por exemplo, os sensores mecânicos são mais propensos a falhar do que os eletrônicos. Por esse motivo, os dados imputados de sensores mecânicos podem faltar com mais frequência.\n",
    "\n",
    "Numa situação como a anterior, se decidirmos continuar com a variável com valores em falta, podemos beneficiar de incluir o tipo de sensor para controlar o bias.\n",
    "\n",
    "\n",
    "#### Faltando não ao acaso, MNAR:\n",
    "\n",
    "Dados ausentes não são aleatórios (MNAR) quando há um mecanismo ou uma razão pela qual valores ausentes são introduzidos no conjunto de dados. Por exemplo, quando uma empresa financeira pede documentos bancários e de identidade de clientes para evitar fraudes de identidade, normalmente, os fraudadores que se passam por outra pessoa não carregam documentos, porque não os possuem, porque são fraudadores. Portanto, existe uma relação sistemática entre os documentos que faltam e o alvo que queremos prever: a fraude.\n",
    "\n",
    "Compreender o mecanismo pelo qual os dados estão ausentes é importante para decidir quais métodos usar para imputar os valores ausentes.\n",
    "\n",
    "==================================================== ===================================================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13764c1c-4710-4108-a278-2b8f0fd08952",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Nesta aula, iremos:\n",
    "\n",
    "- Aprenda a detectar e quantificar valores ausentes\n",
    "\n",
    "- Tente identificar os 3 mecanismos diferentes de introdução de dados ausentes\n",
    "\n",
    "Usaremos o conjunto de dados Toy Loan e o conjunto de dados Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fd849a7-d5a0-4929-9e77-eca6992b0180",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to display the total number columns present in the dataset\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff9fd741-7ef8-4c9b-ac1c-3479b048bb40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# let's load the titanic dataset\n",
    "data = pd.read_csv('/dbfs/FileStore/CDS2023/titanic.csv')\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6188f47c-03e1-429e-ae07-051b3dc2ddad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Em python, os valores ausentes são armazenados como NaN, veja, por exemplo, a segunda linha da variável 'boat'.\n",
    "Podemos quantificar o número total de valores ausentes usando o método **isnull** mais o método sum no dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d60f6a6e-cfcf-4007-b4f0-4fe31f4f5a1c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26ed9721-feb7-4977-be30-4dac21238367",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Faltam 263 valores para Idade, 1014 para Cabine e 2 para Embarcado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10ae3be8-6ab6-4c88-b819-6f770c67d847",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Como alternativa, podemos usar o método mean após isnull para visualizar a porcentagem de valores ausentes para cada variável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef5d06ef-f92d-4aa9-9c23-1424b8d35a84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data.isnull().mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b4cc725-b38b-4e8a-b86e-373c02235e6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Faltam dados nas variáveis Idade (20% de falta), Cabine -na qual o passageiro estava viajando- (77% de falta) e Embarcou -o porto de onde o passageiro entrou no Titanic- (~0,2% de falta)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aad77496-46d1-4c0e-b4fd-ec1ca2d3be72",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Mecanismos de dados ausentes\n",
    "\n",
    "### Dados ausentes não aleatórios (MNAR): valores ausentes sistemáticos\n",
    "\n",
    "No conjunto de dados do Titanic, ambos os valores ausentes das variáveis **idade** e **cabine** foram introduzidos sistematicamente. Para muitas das pessoas que não sobreviveram, não foi possível estabelecer a **idade** que tinham ou a **cabine** em que viajavam. As pessoas que sobreviveram poderiam ser solicitadas por essa informação.\n",
    "\n",
    "Podemos inferir isso olhando os dados?\n",
    "\n",
    "Em uma situação como essa, poderíamos esperar um número maior de valores perdidos para as pessoas que não sobreviveram.\n",
    "\n",
    "Vamos dar uma olhada."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3425dcec-3812-4e74-8472-83612ca0dc53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Vamos criar uma variável binária que indique se falta o valor de cabine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df58d1ab-a137-4421-a5eb-cc18cc2025d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data['cabin_null'] = np.where(data['cabin'].isnull(), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f422d1b-0a4d-44e8-8f3a-3966552f693c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Vamos avaliar a porcentagem de valores ausentes na cabine para as pessoas que sobreviveram versus as que não sobreviveram.\n",
    "\n",
    "A variável Survived assume o valor 1 se o passageiro sobreviveu, ou 0 caso contrário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68318f41-f17f-4eb0-880c-8ac0c7ed73be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group data by Survived vs Non-Survived and find the percentage of nulls for cabin\n",
    "data.groupby(['survived'])['cabin_null'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1200a041-0ce6-4200-a34d-92afe07970b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# another way of doing the above\n",
    "\n",
    "data['cabin'].isnull().groupby(data['survived']).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd4f1615-5e32-44c6-a109-4d201bcc8dac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We observe that the percentage of missing values is higher for people who did not survive (87%), respect to people who survived (60%). This finding is aligned with our hypothesis that the data is missing because after people died, the information could not be retrieved.\n",
    "\n",
    "**Note**: Having said this, to truly underpin whether the data is missing not at random, we would need to get extremely familiar with the way data was collected. Analyzing datasets, can only point us in the right direction or help us build assumptions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bbb4c9f-76c0-4ed5-a916-563d3c6b657f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Exercise:** Let's do the same for the variable age. What can we conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bf3a523-1958-4cab-b50e-504591250f4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e983f63-ff1a-4f13-86f9-2ce3778b66bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Missing data Completely At Random (MCAR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bb56347-62d5-4aeb-a9e6-f4daef14545c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In the titanic dataset, there are also missing values for the variable Embarked. Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18bfe4f0-979e-44f7-98f9-d1c9dd5a36e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data[data['embarked'].isnull()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "932e2c5a-bf1b-4fd1-bf96-2637eaf172d6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "These 2 women were traveling together, Miss Icard was the maid of Mrs Stone.\n",
    "\n",
    "A priori, it does not seem to be an indication that the missing information in the variable Embarked is depending on any other variable, and the fact that these women survived means that they could have been asked for this information.\n",
    "\n",
    "Very likely the values were lost at the time of building the dataset.\n",
    "\n",
    "If these values are MCAR, the probability of data being missing for these 2 women is the same as the probability for values to missing for any other person on the titanic. Of course this will be hard, if possible at all, to prove. But I hope this serves as a demonstration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc37f1f8-f9cb-4d1e-94a6-b29f99c49dee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Missing data at Random (MAR)\n",
    "\n",
    "For this example, I will use the loan book toy dataset from this ficticious peer to peer lending company.\n",
    "\n",
    "We will look at the variables employment and years in employment, both declared by the borrowers at the time of applying for a loan. \n",
    "\n",
    "In this example, data missing in employment are associated with data missing in time in employment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6fc4161-9882-42d2-8777-9db2001defa0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's use the Loan dataset and load the columns of interest for this exercise\n",
    "\n",
    "data = pd.read_csv('/dbfs/FileStore/CDS2023/loan.csv', usecols=['employment', 'time_employed'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfa7ee83-d41b-4513-9851-46abed013a8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# let's check the percentage of missing data\n",
    "\n",
    "data.isnull().mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95e6a1d5-0c4d-4ca1-9ee2-8eb07f5e7a07",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We see that both variables have the same percentage of missing observations roughly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "762270e1-a6ef-49b4-8a92-fc3123919175",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's inspect the different employment types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4716a1ab-4969-4633-b73a-d4d8c39c63bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# number of different employments\n",
    "print('Number of employments: {}'.format(\n",
    "    len(data['employment'].unique())))\n",
    "\n",
    "# Examples of employments\n",
    "data['employment'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c54d7f3a-b849-4d9d-920e-052a2adadc4b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We observe the missing information (nan), and several different employments of the people."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c682ba80-06a7-42fe-9e82-979a2604a9d1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's inspect the variable time employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33a28d32-d4d2-4a9d-a377-b031d1a8bb4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data['time_employed'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebf4986b-c2c3-4b9a-b1fc-862393da2790",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The customer can't enter a value for employment time if they are not employed. They could be students, retired, self-employed, or work in the house. But we can see how these 2 variables are related to each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a41aa48-ab59-44da-b44a-ca0a8e3ff4d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's calculate the proportion of missing data for the time_employed variable for customers who declared employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "603cc886-be57-4910-9203-0e3c5ac3936e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# customers who declared employment\n",
    "t = data[~data['employment'].isnull()]\n",
    "\n",
    "# percentage of missing data in time employed\n",
    "t['time_employed'].isnull().mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d26f705-6688-4627-87eb-266f68021659",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Exercise:** Let´s do the same for those who did not report employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7916660d-1aec-4d9d-ab57-1ecc0b1dd868",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "194871e1-2c46-4827-bdac-4159f2f0ce79",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The number of borrowers who have reported occupation and have missing values in time_employed is minimal. Whereas the customers who did not report an occupation or employment are mostly reporting missing values in the time_employed variable.\n",
    "\n",
    "This further supports that the missing values in employment are related to the missing values in time_employed.\n",
    "\n",
    "This is an example of MAR."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d01014be-b14d-4df5-843e-4417145e9609",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Now let's see how we can deal with missing data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c352ded8-68b2-44d7-aaa3-025af8bab84e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Complete Case Analysis\n",
    "\n",
    "\n",
    "Complete-case analysis (CCA), also called \"list-wise deletion\" of cases, consists in **discarding** observations where values in **any** of the variables are missing. Complete Case Analysis means literally analysing only those observations for which there is information in **all** of the variables in the dataset. \n",
    "\n",
    "### Which variables can I impute with CCA?\n",
    "\n",
    "CCA can be applied to both categorical and numerical variables.\n",
    "\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "CCA works well when the data are missing completely at random (MCAR). In fact, we should use CCA only if we have reasons to believe that data is missing at random, and not otherwise. When data is MCAR, excluding observations with missing information is in essence the same as randomly excluding some observations from the dataset. Therefore the dataset after CCA is a fair representation of the original dataset. \n",
    "\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- Easy to implement\n",
    "- No data manipulation required\n",
    "- Preserves variable distribution (if data is MCAR, then the distribution of the variables of the reduced dataset should match the distribution in the original dataset)\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "- It can exclude a large fraction of the original dataset (if missing data is abundant)\n",
    "- Excluded observations could be informative for the analysis (if data is not missing at random)\n",
    "- CCA will create a biased dataset if the complete cases differ from the original data (e.g., when missing information is in fact MAR or NMAR and not missing at random).\n",
    "- When using our models in production, the model will not know how to handle missing data\n",
    "\n",
    "### When to use CCA\n",
    "\n",
    "- Data is missing completely at random\n",
    "- No more than 5% of the total dataset contains missing data\n",
    "\n",
    "In practice, CCA may be an acceptable method when the amount of missing information is small. Unfortunately, there is no rule of thumb to determine how much missing data is small or negligible. However, as general guidance, if the total amount of missing data is ~5% of the original dataset or less, CCA is a viable option.\n",
    "\n",
    "In many real life datasets, the amount of missing data is never small, and therefore CCA is typically never an option.\n",
    "\n",
    "### CCA and models in production\n",
    "\n",
    "When using CCA, we remove all observations that contain missing information. However, the data that we want to score with our model, may indeed contain missing information. This will pose a problem when using our model in live systems, or as we call it, when putting or models into production: when an observation contains missing data, the model will not be able to handle it. \n",
    "\n",
    "In order to avoid this problem, when putting models into production we need to do 1 of 2 things: either we do not score observations with missing data, or we replace the missing values by another number. We can choose any from the imputation techniques that we will discuss in the following lectures to replace NA in the data to be scored.\n",
    "\n",
    "## In this section:\n",
    "\n",
    "We will use the House Prices dataset to demonstrate how to perform Complete Case Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3620fa6-97eb-46de-a1cd-f8d4f6f8d4ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# let's load the House Prices dataset and explore its shape (rows and columns)\n",
    "data = pd.read_csv('/dbfs/FileStore/CDS2023/houseprice.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7827d2bf-ba35-4215-8588-8aa2881aba79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# to show all the columns of the dataframe in the notebook\n",
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eceafad-0529-4be0-9a44-bbf60c75a7d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We can calculate the percentage of missing values ('NA' - Not available) for each variable and select those with more than 0%.\n",
    "\n",
    "vars_with_na = [var for var in data.columns if data[var].isnull().mean() > 0]\n",
    "vars_with_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "716492a0-b617-4a12-95fb-391d044db573",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# let's find out whether they are numerical or categorical\n",
    "data[vars_with_na].dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7928319a-35b7-4d60-867c-aa70d14f6a36",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "There are both numerical and categorical variables with missing observations. We can see from the variable types that some are float and some are object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "704f7958-7ff0-4e45-ae3d-6015073c9c0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# let's have a look at the values of the variables with missing data\n",
    "\n",
    "data[vars_with_na].head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "031a9f3b-8f9a-4143-9444-718c1e3366e1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Let's find out the percentage of observations missing per variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6e0cc50-6f67-480c-b904-6d57575f0432",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "1 - Calculating the percentage of missing  using the isnull() and mean() methods from pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab5dc12d-4285-45c7-9c7e-552fa0468466",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_na = data[vars_with_na].isnull().mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ed3263b-7eb7-4035-a22d-8d3698d0b36b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "2 - Transforming the array into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e271368-75d2-4c77-9809-370f5246d416",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_na = pd.DataFrame(data_na.reset_index())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0254bd78-ece0-47fc-8d3c-6598ffb897ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "3 - Adding column names to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "724aca8e-0293-4640-bd6e-dadbd77119a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_na.columns = ['variable', 'na_percentage']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eafe3ac4-7a34-4b3d-b08d-5f5f48b2999b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "4 - Ordering the dataframe according to percentage of na per variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "553752d7-3f7c-4ff3-b248-200fc06e851a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_na.sort_values(by='na_percentage', ascending=False, inplace=True)\n",
    "\n",
    "data_na"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bb920b6-98e6-43c7-b663-304f72e457d4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The first 6 variables contain a lot of missing information. So we can't use CCA if we consider those variables, as most of the observations in the dataset will be discarded. We could otherwise use CCA if we omit using those variables with a lot of NA.\n",
    "\n",
    "For this demo, I will ignore the first 6 variables with a lot of missing data, and proceed with CCA in the remaining of the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dbbdc53-4d8a-4788-9e0f-f23af195de25",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Selecting variables with no or less than 5% NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb95c7ea-abd9-4ae3-ab05-6b63cc504e41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vars_cca = [var for var in data.columns if data[var].isnull().mean() < 0.05]\n",
    "vars_cca"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0910c3d7-9733-4a6e-a548-60023d4b18a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Calculating the percentage of observations with complete cases: i.e., with values for all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e60c542e-6106-4ffe-a8a2-d1328d49690f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The method dropna(), discards the observations that contain na in any of the rows / columns\n",
    "\n",
    "len(data[vars_cca].dropna()) / len(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "598f8991-3233-4c03-a9bc-d2c972efc4aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Exercise:** Let's create the complete case dataset. In other words, remove observations with na in any variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d506a40-2d42-4cd6-8dc3-27b17bda1ad1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64b6afb7-0a27-4302-b226-caa45967a0fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's plot the histograms for all numerical variables in the complete case dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2177310-f767-42c4-bba2-5a91f414f2e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_cca.hist(bins=50, density=True, figsize=(16, 16))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "987410e2-e217-4c29-9b9d-c6a1d37bdfcf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's check the distribution and the density of a few variables before and after CCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9b775c9-dc3f-40a7-8572-1424e2397549",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# original data\n",
    "data['GrLivArea'].hist(bins=50, ax=ax, density=True, color='red')\n",
    "\n",
    "# data after cca, the argument alpha makes the color transparent, so we can see the overlay of the 2 distributions\n",
    "data_cca['GrLivArea'].hist(bins=50, ax=ax, color='blue', density=True, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "223618aa-1e85-4378-982f-2879804b54c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# original data\n",
    "data['GrLivArea'].plot.density(color='red')\n",
    "\n",
    "# data after cca\n",
    "data_cca['GrLivArea'].plot.density(color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7cba559-f05e-4b0b-b7f1-ee9bd5eb5213",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# original data\n",
    "data['BsmtFinSF1'].hist(bins=50, ax=ax, density=True, color='red')\n",
    "\n",
    "# data after cca\n",
    "data_cca['BsmtFinSF1'].hist(bins=50, ax=ax, color='blue', density=True, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78941649-e1b9-4770-9525-8037cac87412",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# original data\n",
    "data['BsmtFinSF1'].plot.density(color='red')\n",
    "\n",
    "# data after cca\n",
    "data_cca['BsmtFinSF1'].plot.density(color='blue')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15657e03-3e36-482f-8727-ef7814f9e8b7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As we can see from the above plots, the distribution of the selected numerical variables in the original and complete case dataset is very similar, which is what we expect from CCA if data is missing at random and only for a small proportion of the observations.\n",
    "\n",
    "In the next cells I will explore the distribution of categorical variables. To do so, I will evaluate the percentage of observations that show each of the unique categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbf510e7-7387-4235-b41d-b8a3e2caaff9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#The following function captures the percentage of observations for each category in the original and complete case dataset\n",
    "# and puts them together in a new dataframe\n",
    "\n",
    "\n",
    "def categorical_distribution(df, df_cca, variable):\n",
    "    tmp = pd.concat(\n",
    "        [\n",
    "            # percentage of observations per category, original data\n",
    "            df[variable].value_counts() / len(df),\n",
    "\n",
    "            # percentage of observations per category, cca data\n",
    "            df_cca[variable].value_counts() / len(df_cca)\n",
    "        ],\n",
    "        axis=1)\n",
    "\n",
    "    # add column names\n",
    "    tmp.columns = ['original', 'cca']\n",
    "\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a654d2c-d892-431c-b896-3704f7e2d0d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# run the function in a categorical variable\n",
    "categorical_distribution(data, data_cca, 'BsmtQual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "526781a0-39d3-43b0-b080-7f5b46dc8bfa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categorical_distribution(data, data_cca, 'MasVnrType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b21a606a-58b2-4258-a17f-7438e45c84c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categorical_distribution(data, data_cca, 'SaleCondition')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e34625ca-bac1-4c3d-b07d-60e76d14e146",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As we can see from the output of the cells above, the distribution of houses in each of the categories, is very similar in the original and complete case dataset, which again, is what is expected if the data is missing completely at random, and the percentage of missing data is small."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c318203-2ded-4b5e-b909-0a16167378bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Now let's see another method to deal with missing data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76fbfc77-9c0e-40df-b87e-a98fd808fcee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Mean / Median imputation\n",
    "\n",
    "Imputation is the act of replacing missing data with statistical estimates of the missing values. The goal of any imputation technique is to produce a **complete dataset** that can be used to train machine learning models.\n",
    "\n",
    "Mean / median imputation consists of replacing all occurrences of missing values (NA) within a variable by the mean (if the variable has a Gaussian distribution) or median (if the variable has a skewed distribution).\n",
    "\n",
    "**Note the following**:\n",
    "\n",
    "- If a variable is normally distributed, the mean, median and mode, are approximately the same. Therefore, replacing missing values by the mean and the median are equivalent. Replacing missing data by the mode is not common practice for  numerical variables.\n",
    "- If the variable is skewed, the mean is biased by the values at the far end of the distribution. Therefore, the median is a better representation of the majority of the values in the variable.\n",
    "- For discrete variables casted as 'int' (to save memory), the mean may not be an integer, therefore the whole variable will be re-casted as 'float'. In order to avoid this behaviour, we can replace NA with the median instead. The median will inevitably be an integer / discrete value as well.\n",
    "\n",
    "\n",
    "### Which variables can I impute with Mean / Median Imputation?\n",
    "\n",
    "The mean and median can only be calculated on numerical variables, therefore these methods are suitable for continuous and discrete numerical variables only.\n",
    "\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "- Data is missing completely at random (MCAR)\n",
    "- The missing observations, most likely look like the majority of the observations in the variable (aka, the mean / median)\n",
    "\n",
    "If data is missing completely at random, then it is fair to assume that the missing values, are most likely very close to the value of the mean or the median of the distribution, as these represent the most frequent / average observation.\n",
    "\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- Easy to implement\n",
    "- Fast way of obtaining complete datasets\n",
    "- Can be integrated in production (during model deployment)\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Distortion of the original variable distribution\n",
    "- Distortion of the original variance\n",
    "- Distortion of the covariance with the remaining variables of the dataset\n",
    "\n",
    "When replacing NA with the mean or median, the variance of the variable will be distorted if the number of NA is big respect to the total number of observations, leading to underestimation of the variance.\n",
    "\n",
    "In addition, estimates of covariance and correlations with other variables in the dataset may also be affected. Mean / median imputation may alter intrinsic correlations since the mean / median value that now replaces the missing data will not necessarily preserve the relation with the remaining variables.\n",
    "\n",
    "Finally, concentrating all missing values at the mean / median value, may lead to observations that are common occurrences in the distribution, to be picked up as outliers.\n",
    "\n",
    "\n",
    "### When to use mean / median imputation?\n",
    "\n",
    "- Data is missing completely at random\n",
    "- No more than 5% of the variable contains missing data\n",
    "\n",
    "Although in theory, the above conditions should be met to minimise the impact of this imputation technique, in practice, mean / median imputation is very commonly used, even in those cases when data is not MCAR and there are a lot of missing values. The reason behind this, is the simplicity of the technique.\n",
    "\n",
    "\n",
    "### Final note\n",
    "\n",
    "Replacement of NA with mean / median is widely used in the data science community and in various data science competitions. See for example the winning solution of the KDD 2009 cup: [\"Winning the KDD Cup Orange Challenge with Ensemble Selection\"]( http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf).\n",
    "\n",
    "Typically, mean / median imputation is done together with adding a binary \"missing indicator\" variable to capture those observations where the data was missing (see lecture \"Missing Indicator\"), thus covering 2 angles: if the data was missing completely at random, this would be captured by the mean /median imputation, and if it wasn't this would be captured by the additional \"missing indicator\" variable. Both methods are extremely straight forward to implement, and therefore are a top choice in data science competitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f984d79-ed67-4314-b203-643d8e2f182b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# to split the datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5a5c4da-0170-46d3-bf77-54cf45e34751",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Let's put into practice with Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61c74ce1-ade2-46d6-a237-6567ee048399",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load the Titanic Dataset with a few variables for demonstration\n",
    "\n",
    "data = pd.read_csv('/dbfs/FileStore/CDS2023/titanic.csv', usecols=['age', 'fare', 'survived'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d75d666-51cb-4a6f-ae85-b4606da03287",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# let's look at the percentage of NA\n",
    "\n",
    "data.isnull().mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd13b0d3-d1f1-4109-92f9-7c312a167460",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The only variable with missing data is Age, with ~20% of missing observations.\n",
    "\n",
    "### Imputation - important\n",
    "\n",
    "Imputation should be done over the training set, and then propagated to the test set. This means that the mean / median to be used to fill missing values both in train and test set, should be extracted from the train set only. And this is to avoid overfitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2862c0d-0da7-47e4-9b53-e88759d82d35",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "First, let's separate the data into training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "542a4d50-660f-486a-bb10-0418a9ca457c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['age', 'fare']],  # predictors\n",
    "    data['survived'],  # target\n",
    "    test_size=0.3,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e901d465-4503-42fc-a402-bf5a34646b85",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's explore the missing data in the train set. The percentages should be fairly similar to those of the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e719367-de71-411c-a789-708ea7de7f2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.isnull().mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f4ec4f9-4b55-490f-a235-4b9728843dc2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's make a function to fill missing values with the mean or median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "838526e6-7fdc-4c55-8f84-8338adfabdbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The function takes the dataframe, the variable, and the value of the mean or median as parameters and returns the variable with the filled na.\n",
    "\n",
    "\n",
    "def impute_na(df, variable, mean_median):\n",
    "\n",
    "    return df[variable].fillna(mean_median)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bbf9799-ba0d-4c86-84fe-a454e0003fbb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Exercise:** What is the mean and median age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1f240ac-6271-4321-98f5-0ae19c4b6d24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d4a890b-2c62-4430-9502-b30577ddd4bf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's create a new variable with the missing values replaced, using the function we created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d294cbe-47e9-4ab1-be34-034b08db80ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# first replace with the median\n",
    "X_train['Age_median'] = impute_na(X_train, 'age', median)\n",
    "\n",
    "# now replace with the mean\n",
    "X_train['Age_mean'] = impute_na(X_train, 'age', mean)\n",
    "\n",
    "# the mean contains many decimals, so I round to 1, using # the round function from numpy\n",
    "\n",
    "X_train['Age_mean'] = np.round(X_train['Age_mean'], 1)\n",
    "\n",
    "X_train.head(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ebf0359-f605-4c22-a394-6a8635c80530",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Look at the rows with missing data (NaN) in Age, and see how in the new variables those were replaced by either 28 (median) or 30 (mean)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acd7bced-6096-47d7-ba5a-dbd6de27871c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's see if there is a variance change after the imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcee47cc-b3a1-496d-b76e-b549a257e56a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('Original variable variance: ', X_train['age'].var())\n",
    "print('Variance after median imputation: ', X_train['Age_median'].var())\n",
    "print('Variance after mean imputation: ', X_train['Age_mean'].var())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0ac8dc5-b484-48ae-b980-696d08fdea22",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can see a change in the variance after mean / median imputation. This is expected, because the percentage of missing data is quite high in Age, ~20%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1c3219f-cdb7-4051-b3a0-2777d31a6be1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As expected, the variance is underestimated, because now many values are the same ==> either the mean or the median value. We can see through graphs that the distribution has changed, accumulating more values towards the median or median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d725b887-3f39-4d84-80b2-0c950d5c9f85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# original variable distribution\n",
    "X_train['age'].plot(kind='kde', ax=ax)\n",
    "\n",
    "# variable imputed with the median\n",
    "X_train['Age_median'].plot(kind='kde', ax=ax, color='red')\n",
    "\n",
    "# variable imputed with the mean\n",
    "X_train['Age_mean'].plot(kind='kde', ax=ax, color='green')\n",
    "\n",
    "# add legends\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(lines, labels, loc='best')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e69eaf6-b9cf-486d-a8d7-87cd1d0cc183",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As mentioned above, the mean / median imputation distorts the original distribution of the variable Age. The transformed variable shows more values around the mean / median values.\n",
    "\n",
    "**Is this important?**\n",
    "\n",
    "It depends on the machine learning model you want to build. Linear models assume that the variables are normally distributed. Mean / median imputation may distort the original normal distribution if the % of missing data is high. Therefore the final imputed variable will no longer be normally distributed, which in turn may affect the linear model performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7cf86b1-7c5c-4cc0-b72c-66c6ea323820",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We also said that mean / median imputation may affect the relationship with the other variables in the dataset, let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f21514a-9ee9-4680-b2e9-2d54eb1b4466",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train[['fare', 'age', 'Age_median', 'Age_mean']].cov()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2812aaca-38d1-427f-8add-5139f507650d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We see indeed that the covariance between Age and Fare is changed after the mean / median imputation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8eae4cab-c983-40d4-8b9d-ef7c801af0e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Finally, we mentioned that mean / median imputation may lead to observations that are normal, to look like outliers or in other words, mean / median imputation may lead to an increase in the apparent number of  outliers. Let's use a boxplot to see if it happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "309d468b-012f-4397-a57c-4c76e0d338d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train[['age', 'Age_median', 'Age_mean']].boxplot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7e62c6f-8d73-4d6a-8d95-7e5025457441",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "From the boxplot above, we can see that after the imputation not only we have more outliers on the higher Age values, but we have now outliers as well for the lower values of Age.\n",
    "\n",
    "**Is this important?**\n",
    "\n",
    "If we are after true outliers, we need to keep this behaviour in mind, to make sure that we are neither masking nor creating artificial outliers with our imputation technique. In practice, we normally don't check for this behaviour at all. But I think it is important to know that is happening."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6faaaed-5d7b-476d-8618-a0c259f3d414",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Authors:** Juliana da Mota Coelho, Camila Mizokami.\n",
    "\n",
    "**References:**\n",
    "\n",
    "https://pandas.pydata.org/docs/user_guide/missing_data.html \n",
    "\n",
    "https://chartio.com/resources/tutorials/how-to-check-if-any-value-is-nan-in-a-pandas-dataframe/ \n",
    "\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/03.04-missing-values.html \n",
    "\n",
    "https://towardsdatascience.com/3-ultimate-ways-to-deal-with-missing-values-in-python-ac5a17c53787"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Class_4_Missing_Data_student",
   "notebookOrigID": 2794059949142655,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "fe_test",
   "language": "python",
   "name": "fe_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
